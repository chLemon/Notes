
# 模板



**时间**：
**杂志**：
**摘要**：

**关键词**：

# Software Reliability Engineering - A Review软件可靠性工程-回顾
软件可靠性工程-回顾

**时间**：2011年9月
**杂志**：International Journal of Applied Physics and Mathematics
**摘要**：
略
**关键词**：
reliability， waterfall ，prototyping ，incremental，rapid，evolutionary，agile
可靠性，瀑布模型，原型制作，增加的，快速，进化，敏捷

## 总结

1. 里面有传统可靠性的浴盆曲线和理想化的软件可靠性曲线。
2. 有常见的软件开发模型的简介，有瀑布模型、原型制作、增量开发、螺旋发展、快速应用开发（RAD）、进化发展方法、Rational统一过程、基于组件的软件开发。
3. 有计算机辅助软件工程、IDE、敏捷开发（极限编程XP、Scrum）的简介。
4. 至于文章本身提出的那个东西，就是说要先建模算一算可靠性，直接算可能有困难。但是啥有用的东西都没有。

# Deterministic Models of Software Aging and Optimal Rejuvenation Schedules软件老化和最佳复兴计划的确定性模型
软件老化和最佳复兴计划的确定性模型

**时间**：2007
**杂志**：
**摘要**：
研究对象：服务器Axis Soap Server 1.3
对老化建模，从而进行Rejuvenation。SLA约束、

建模算法：样条插值拟合
**关键词**：

## 总结

1. 在介绍中提到了老化、Rejuvenation的介绍，两种基本的Rejuvenation思路：定时，积极（根据建模）。
2. 用某些指标来评价老化：服务器每秒可处理的最大请求数。
3. 假设性能下降与负载有关的函数。假设模型可以足够精确的建模。
4. 介绍了建模思路：分析建模和基于度量建模
5. 建模过程：分段用样条拟合
6. 假设老化指标只取决于单个负载指标。或者多个负载指标的简单函数。
7. 用方差分析进行了模型验证
8. 改进了方差分析法，引入了方差容忍度
9. 分析了如何得出最佳Rejuvenation的时间，此处没有细看
10. 实验通过10台客户端连接1台服务器来注入负载。
11. 收集的系统参数有：
  + free memory：available memory in the JVM of the SOAP
server
  + cpu_user： % of CPU time used by the user applications,
  + cpu_system：操作系统使用的CPU时间的百分比，
  + cpu_idle：CPU空闲的时间的百分比，
  + request_per_sec：SOAP服务器的吞吐量，以每秒执行的请求数为单位，
  + min_lat：请求延迟最小观测值
  + maxlat：请求延迟最大观测值
  + avg lat：请求延迟平均值。
12. 实验方法：以超过服务器容量的某一个固定值持续加压
13. 老化指标：每秒请求数。负载指标：经选择，用了自上次重启以来的请求数。
14. 图像的曲线都是很平滑的，先上升，然后缓慢单调下降的样子。【随着总请求数越来越多，每秒的请求就越小，老化了。】

# Basic Concepts and Taxonomy of Dependable and Secure Computing可靠和安全计算的基本概念和分类
可靠和安全计算的基本概念和分类

这篇好像是大佬的综述
**时间**：2004
**杂志**：IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 1, NO. 1, JANUARY-MARCH 2004 
**摘要**：
就是各种定义。
**关键词**：
Dependability, security, trust, faults, errors, failures, vulnerabilities, attacks, fault tolerance, fault removal, fault forecasting
可靠性，安全性，信任性，故障，错误，故障，漏洞，攻击，容错，故障消除，故障预测
## 总结

非常详尽的定义

# Detecting Application-Level Failures in Component-Based Internet Services在基于组件的Internet服务中检测应用程序级故障
在基于组件的Internet服务中检测应用程序级故障

作者一个是斯坦福的，一个是MIT的
**时间**：2005
**杂志**：IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 16, NO. 5, SEPTEMBER 2005 
**摘要**：
大多数Internet服务（电子商务，搜索引擎等）都存在故障。
快速检测这些故障可能是提高系统可用性的最大瓶颈。
我们介绍方法Pinpoint，一种通过以下方法在Internet服务中自动进行故障检测的方法：1）观察服务的底层内部结构行为； 2）将系统的多数行为建模为正确； 3）将这些行为中的异常检测为故障的可能症状。
不需要任何先验的特定于应用程序的信息，Pinpoint在我们的实验中正确地检测出了89％–96％的重大故障，与此同时，当前的通用应用技术检测出了20％–70％。
**关键词**：
Anomaly detection, application-level failures, Internet services.
异常检测，应用程序级别的故障，Internet服务。

## 总结

1. 研究的是应用程序级的故障：会影响用户可见的一些功能，但是不会引起系统崩溃一类的运营商可检测到的系统级故障
2. 无需先验信息，对正常状态进行建模。
3. 监控内部组件的trace形状：客户请求后经过的部件名称。监控部件之间的交互情况。
4. 实验对象：J2EE应用程序
5. 主要关注在故障发生后尽快检测到
6. 监测方法：写在了J2EE上
7. 故障注入研究，参考文献4,18-21，列举了一部分，没有详细步骤
8. 计算P的时候通过min(0, score-a)过滤掉大于a的一些值
9. 组件交互的计数与请求路径分析有一定程度上的互补。
10. 用PCFG对路径进行了建模，从这里就与我的研究无关了。
11. 本篇有简略译文。


# A Measurement-Based Model for Estimation of Resource Exhaustion in Operational Software Systems基于测量的运营软件系统资源枯竭估计模型
基于测量的运营软件系统资源枯竭估计模型

**时间**：1999
**杂志**：
**摘要**：

主要研究软件老化。本文考虑了系统的工作负荷，函数的自变量之一。本文提出了一个基于度量的模型，来估计操作系统资源的耗尽率，自变量为时间和工作负载状态。用基于Unix系统收集到的工作量和资源使用情况构建了半马尔科夫奖励模型。先用统计聚类分析对工作量的状态进行了聚类，然后根据每种在不同状态下的资源枯竭率，为该模型定义奖励函数。然后求解该模型以获得**趋势**以及资源的估计**耗尽率**和**耗尽时间**。


**关键词**：

## 总结

1. 研究老化，主要原因：操作系统资源的耗尽，数据损坏和数字错误累积。导致系统崩溃或挂起。
2. 常见情况：**内存膨胀和泄漏**，**未释放的文件锁**，数据损坏，存储空间碎片以及舍入错误的累积
3. 预测资源消耗的时候考虑了工作负载。
4. 相关工作中提到：
   1. 时间为变量预测系统资源的方法
   2. 有一些文献说明了资源、负载与失效的相关性。
   3. 别的工作负载指标：CPU使用率、内存使用率
   4. 性能的单词用了performability
5. 马尔科夫不太懂，没有细看。简单的说，应该是预测一个状态到另一个状态转换的概率。
6. 10分钟一次，监控了3个月：系统资源状态、进程状态、文件系统信息【/tmp】、网络相关、磁盘IO，共100多个此类参数【和sar的差不多，只不过多了进程信息？】
7. 要预测的值：usedSwapSpace和realMemoryFree。建模用的数据是最长的采样时间内的数据【重启或发生了故障则重新采样】
8. 工作负载的表示：工作负载与CPU和I/O有关，故采用cpuContextSwitch【测量间隔内，进程的上下文切换数量】、sysCall【系统调用数】、pageIn【从文件系统或交换设备分页的页面数，就叫page-in】、pageOut
9. 对于每个工作负载的点【相当于一个四维空间的点】进行聚类，算法用的Hartigan【一种k-means聚类算法】。聚类发现一些状态时轻量工作状态，一些是高负载。
10. 计算状态转移概率【通过简单除法】，构建转移矩阵。半马尔科夫好像还要状态持续时间，反正根据分布大概定了一个？然后验证了一下结果，效果很不错。
11. 这里有点看不懂了，反正是通过奖励函数，利用半马尔科夫模型对要预测的两个值进行了预测
12. 计算斜率的方法[20]：这个斜率好像是大量样本的总斜率，跟我要的不一样。
13. 最后这个结果有点迷，看不懂


# A Best Practice Guide to Resource Forecasting for Computing Systems计算系统资源预测的最佳实践指南
计算系统资源预测的最佳实践指南

**时间**：2007
**杂志**：
**摘要**：
在本文中，我们基于预测Apache Web服务器性能变量以及预测实际电信系统的呼叫可用性的经验，提出了建立经验模型的最佳实践指南。为了证实所提供的指南，并逐步演示我们的方法，我们对**响应时间**，Apache Web服务器系统的**可用物理内存**量以及工业电信系统的呼叫call可用性进行建模和预测。此外，我们为a）基准交叉验证三个**变量选择**的方法，b）基准交叉验证四个**经验模型构建**的方法以及c）**敏感性分析**  提供了具体的结果。本最佳实践指南旨在协助系统地配置建模方法，以实现最佳估计和预测结果。

**关键词**：
Apache web server, failure forecasting, monitoring,
non-parametric modeling, prediction of resource utilization,
quantitative analysis, statistical modeling, telecommunication
systems.

Apache Web服务器，故障预测，监视，非参数​​建模，资源利用预测，定量分析，统计建模，电信系统。

## 总结

1. 本篇文献非常有用，基本上阐述了在当时的常用方法，并进行了总结，还有完整的实验和分析
2. Introduction里的很多也非常有用，可以直接用
3. 补丁、更新会把测试过的系统编程未测试的系统，引入新的错误，所以需要预测
4. 预测了Apache服务器中的响应时间和可用物理内存。电信系统的那个例子没细看。
5. 主要过程：数据选择【向前选择，向后消除，PWA概率包装】，建模【**多元线性回归、UBF、RBF、SVM**】，敏感性分析【删除一个看看模型的指标怎么样，后来发现敏感性与目标值的相关性关系不大】
6. 选择好的数据子集要比选模型重要的多
7. 介绍了大量之前别人用过的模型，文献
8. 数据集分成了三份，【按时间分的？从图上看是这样的】将第一段用于参数化模型，第二部分对模型进行交叉验证并限制过度拟合，第三部分用于对模型的泛化性能进行评估。一二段都喂给模型
9. 数据有峰值，处理方法：一段时间窗口内的中位数median，感觉平均值也行？或者就是平均值？
10. 数据：系统变量一类的和网络相关的，还有一阶导数
11. 响应时间预计：
    1. 实际数据：整体缓慢上升，有非常多的峰值，整体是个锯齿
    2. 中位数处理后，整体单调上升，最后一段略微下降一点点就平了
    3. 大概每6h有一次峰值
    4. 短期预计选出来的变量有：
       1. 新进程数
       2. 硬盘写入块数
       3. eh0_trans_pkts
       4. lo_recv_pkts
       5. SwapOutCounter
       6. si_slab_cache
       7. si_size_256
       8. ContextSwitches的导数
       9. CachedMemory的导数
    5. 长期的变量有：
       1. 新进程数
       2. eh0_recv_pkts
       3. ContextSwitches
       4. TimeIdelMode
       5. io_trans_bytes
       6. SwapInCounter
       7. si_size_256
       8. si_size_32
       9. ContextSwitches的导数
12. 可用内存预计
    1. 数据趋势：先下降，然后到一个地方后开始上升
    2. 变量有：
       1. t-1时刻的可用物理内存
       2. TimeUserMode
       3. 新进程数的导数
       4. si_files_cache

# Quantifying Temporal and Spatial Correlation of Failure Events for Proactive Management量化故障事件的时间和空间相关性以进行主动管理

量化故障事件的时间和空间相关性以进行主动管理

**时间**：2007
**杂志**：
**摘要**：

故障事件在时空方面表现出很强的相关性。 在本文中，我们开发了具有可调时标参数的**球形协方差模型**以量化时间相关性，并建立了随机模型以表征空间相关性。 进一步扩展了模型，以考虑到应用程序分配的信息，以发现故障实例之间的更多关联。 我们根据故障事件的相关性对它们进行聚类，并预测其未来的发生。
在生产联盟系统Wayne State Grid上的实验结果表明，我们的预测系统进行的离线和在线预测可以预测72.7％至85.3％的故障发生，并捕获集群联盟环境中的故障相关性。

**关键词**：

## 总结
1. 主要考虑的是故障之间的时间相关性和空间相关性
2. 时间相关性：a.短时间内多个节点同时发生一个故障；b.故障在解决前多次出现
3. 空间相关性：a.故障几乎同时发生在多个节点上【一个程序要用多个节点，有bug都得坏】；b.节点故障会导致别的节点的另一种故障【一个坏了会传错误数据】
4. 实验对象，他们学校的一个计算集群，最小单位就是一台计算机……
5. 收集的信息：失效签名：内存、CPU、I/O、包
6. 聚类算法？
7. 失效是个重尾分布，而且软件故障最严重（相比于硬件和全部）
8. 时间相关性：用时间差衡量距离，定义了一个球形协方差矩阵【没看懂】
9. 空间相关性：主要是计算失效数，拿概率算的。
10. 离线预计算法4+1：MEAN：以先前度量的平均值作为预测；  LAST：使用最后一个度量；  AVE（n）：使用最近n个小节的平均值；  AR（m）：是自回归的； 一种人工神经网络算法NN（n），使用最后n个数据来更新神经网络并预测故障【3个隐藏层】。
11. 在线预计：拿0~t的数据来预测，然后对比t~T的结果。

# Online Reliability Prediction via Motifs-Based Dynamic Bayesian Networks for Service-Oriented Systems面向服务的系统通过基于Motifs的动态贝叶斯网络进行在线可靠性预测
面向服务的系统通过基于Motifs的动态贝叶斯网络进行在线可靠性预测


**时间**：2016
**杂志**：IEEE Transactions on Software Engineering
**摘要**：

面向服务的系统系统（SoS）将系统视为服务，并通过服务组合技术外包外部组件系统来构建健壮的增值SoS。 为了应对在动态和不确定的运行环境下运行的松耦合SoS，为确保整体服务质量（QoS）的目的而对组件系统进行在线可靠性预测通常是一个重大挑战。 这也是通过优化服务选择以确保可靠的系统构建来保证SoS的运行时QoS的前提。 我们为面向服务的SoS中的组件系统提出了一种新颖的在线可靠性时间序列预测方法。 我们利用概率图形模型（PGM）来产生接近未来的时间序列预测。 我们通过从广泛使用的真实Web服务中收集的调用记录来评估该方法。 实验结果证实了该方法的有效性。


**关键词**：Index Terms—Online reliability prediction, time series, service-oriented computing, system of systems

索引词-在线可靠性预测，时间序列，面向服务的计算，系统系统

## 总结

1. 本文没有详细阅读
2. 主要是针对System of Systems，好像会有一些独特的问题，本文重点在预测可靠性
3. 在线可靠性时间序列预测
4. 历史参数：响应时间，吞吐量，可靠性，用概率图像模型PGM分析。对历史参数预处理，分成等长的时间序列。然后用主题的概念来描述时间序列的模式。然后用马尔科夫表达序列间的关系，生成条件概率表CPT，CPT与PGM一起用于预测。主要是基于动态贝叶斯网络，整合了时间序列。
5. 论文15中有简要介绍





# Seer: A Lightweight Online Failure Prediction Approach 一种轻量级的在线故障预测方法
Seer：一种轻量级的在线故障预测方法

**时间**：2017
**杂志**：IEEE Transactions on Software Engineering
**摘要**：

**关键词**：

## 总结
1. 从程序内部收集信息会产生过多的运行时开销，所以现有方法通常会避免使用
2. Seer是通过硬件性能计数器（HPC）来收集数据的，在硬件层面收集数据，如CPU驻留计数器来收集执行的指令数和采取的分支数量
3. 与此同时还可以结合系统层次收集到的进程数、CPU、内存、网络利用率来加强预测效果。【这个他好像没做，看了眼图，确实没有】
4. 现在大部分的预测都是把软件当黑盒子，可以考虑白盒拿到更内部的数据。不这么做的主要问题是开销太大。
5. 本文未精读。
6. 先把历史数据输入，然后选出一些可以在运行时监控的函数，然后从这些函数的历史数据里收集信息，用于识别出一些候选函数。然后再在候选函数里选，选出seer函数，用seer函数预测。
7. 过滤历史数据：1. 过滤掉error级别的，因为这时候已经发生了，该函数对预测没啥用。2. 过滤掉执行次数太多的，考虑开销
8. 筛选变量：对每一个函数都构建了一个决策树，然后把F值高的留了下来
9. 滑动窗口：函数做出的一系列的预测用于分析。背后可能的原理[34]：程序中的缺陷会不断地传播，感染更多的程序状态，那么一段时间内的一系列预测可以提高预测准确性。随着时间流逝，与正常值的偏差可能增加。
10. 每个seer函数在调用后都会给个预测值，T或F，一个执行的所有预测值叫health index
11. 滑动窗口是用每个seer函数的最后l个预测值去预测会不会失效。然后把窗口内的分数做个加和这样。
12. 感觉很有趣的东西，没时间细看了。
13. TOT_INS计算执行的机器指令的数量。BRN_TKN计算采取的分支数。LST_INS对执行的加载和存储存储器指令的数量进行计数。

# DAC-Hmm: detecting anomaly in cloud systems with hidden Markov models
DAC-Hmm：使用隐藏的马尔可夫模型检测云系统中的异常


**时间**：2015
**杂志**：
**摘要**：
云计算系统的异常检测解决方案必须在运行时运行，而且不需要事先了解正常或异常行为。 本文提出了一种基于隐马尔可夫模型的无监督在线异常检测方案。 我们的算法基本上是分布式的，并在云上的每台计算机上本地运行，以实现高可扩展性。 在真实数据集上进行的实验证实了以下事实，即我们的算法可以为一系列系统异常实现高检测精度，而对云基础架构的开销却很小。 
**关键词**：

## 总结
我感觉这个跟我没啥关系，云计算，黑盒的，而且还是无监督异常检测，不是预计

# The Time Dimension in Predicting Failures: a Case Study预测故障的时间维度：一个案例研究

**时间**：2013
**杂志**：
**摘要**：

**关键词**：
## 总结
1. 这篇文章复制不了，好坑
2. 时间窗口

# Fundamental Concepts of Dependability

**时间**：2001
**杂志**：
**摘要**：

**关键词**：

## 总结
和可靠性，故障，失效有关的一些概念。

# A Survey of Online Failure Prediction Methods
重要！！！

**时间**：
**杂志**：
**摘要**：

**关键词**：

本文有目前的方法分类，还有一个大表格，非常有用，之后整理出来。



# A Survey of Software Aging and Rejuvenation Studies软件老化和复兴研究概述

**时间**：
**杂志**：
**摘要**：

**关键词**：

## 总结
1. 预测值与真实值的差是不是也可以用，有文章用此作为了开始老化的起点现象。 
2. 记得考虑负载的问题。

# Towards assessing representativeness of fault injection-generated Failure Data for Online Failure Prediction面向评估故障注入生成的故障数据的代表性，以进行在线故障预测

**时间**：2015
**杂志**：
**摘要**：

**关键词**：

注入的软件故障是否有代表性是最后生成的故障数据有效的一个必要条件。生成的故障相关的数据的代表性依旧是个仍未解决的问题。在这项工作中，我们提出了使用G-SWFIT逼真的软件故障注入技术来评估故障相关数据的代表性的初步研究。我们在这里解决代表性估计和评估的概念和度量标准的定义。

## 总结

1. 主要研究的是软件注入的故障是否有代表性的问题。
2. 提到了G-SWIFT：通用软件故障注入技术。Time Domain那篇文章也是用的这个。



   [11] J. A. Duraes and H. S. Madeira, “Emulation of software faults: A
field data study and a practical approach,” IEEE Trans. Softw. Eng.,
pp. 849–867, 2006.

   

![image-20200528120319033](C:\Users\55012\AppData\Roaming\Typora\typora-user-images\image-20200528120319033.png)

![image-20200528120331247](C:\Users\55012\AppData\Roaming\Typora\typora-user-images\image-20200528120331247.png)


# A Machine Learning-based Framework for Building Application Failure Prediction Models基于机器学习的框架，用于构建应用程序故障预测模型
基于机器学习的框架，用于构建应用程序故障预测模型

**时间**：2015
**杂志**：
**摘要**：

$$F^2PM$$,Framework for building Failure Prediction Models。

一个基于机器学习的框架，用来预测RTTF：the Remaining Time to Failure。

F2PM用系统参数来构建，故与应用程序无关。

F2PM可以选择与失效更相关的系统参数来建模。同时输出一套指标，用于度量模型的好坏，包括模型的准确度和构建时间等。

**关键词**：

## 总结

1. 主要考虑的是内存泄漏和线程未终止
2. 主要思路：收集系统参数，然后用多个机器学习方法进行预测，提供评估指标供用户挑选。
3. 收集的参数：
   1. Tgen是表示自系统启动以来经过的时间的时间戳。  
   2. nth是系统中活动线程的数量；  
   3. Mused是系统中运行的应用程序使用的内存量；  
   4. Mfree是可供应用程序免费使用的内存量； 
   5. Msharedis用于应用程序共享的缓冲区的内存量；  
   6. Mbuff是底层操作系统用于缓冲数据的内存量；  
   7. Mcached是用于缓存磁盘数据的内存量；  
   8. SWused是当前使用的交换空间量；  
   9. SWfree是交换空间的数量，当前可用；  
   10. CP Uus是专用于用户空间进程的CPU时间的百分比；  
   11. CP Uni是具有正尼斯值（较低的调度优先级）的用户级进程占用的CPU时间的百分比；  
   12. CP Usysis在内核模式下花费的CPU时间的百分比； 
   13. CP Uiowis等待I / O操作完成所花费的CPU时间的百分比；  
   14. CP Ust是虚拟机管理程序为另一个虚拟处理器提供服务时，虚拟CPU等待实际CPU的时间百分比。  
   15. CP Uid是完成无效工作（即系统负载不足）所花费的CPU时间的百分比。
4. 数据处理：
   1. 对一个时间窗口内的数据进行了聚合（平均值）：减少数据量，加快训练；消除掉因为操作系统调度引起的单个数据点上的偏差
   2. 对一个时间窗口的数据算了斜率，简单的用最两边的数据：认为崩溃点附近斜率会更大？
   3. 计算了每个数据收集时间戳的间隔，间隔会变化，增大。并与客户端的响应时间呈现强正相关。可以用间隔来拟合响应时间，从而无需对客户端进行修改。同时也可以对失效的判定进行微调。
   4. 特征选择：岭回归【Lasso Regularization】

5. 使用的模型：
   1. 线性回归
   2. M5P：具有线性回归可能性的决策树
   3. REP-Tree：快速决策树
   4. Lasso
   5. SVM
   6. 最小二乘支持向量机
6. 故障注入
   1. 认为生成内存泄漏和未终止的线程
   2. 内存泄漏：定期分配可变大小的连续内存块，并将虚拟内存写入。
   3. 内存泄漏的注入：用2种分布来注入：正态分布来定义每次泄漏的小打、指数分布用于定义内存泄漏的间隔时间
   4. 未终止线程的时间间隔：指数分布
   5. 分布参数用户定义
7. 时间收集的间隔大约是1.5s【会因为CPU的调度和工作负载有变化】
8. 数据传输：TCP/IP协议传输到另一台机器上
9. 一台机器用来发请求，并且记录响应时间；另一台机器搭建一个网页服务器，然后在每次请求的时候，概率性的泄漏内存或生成新线程。
10. 每次崩溃的时候，服务器虚拟机自动重启。收集一周的数据
11. 当RTTF很大的时候，预测的值会偏小。作者认为是因为当故障不断累积的情况下，性能下降，从而导致异常发生率降低，从而实际时间会变长。
12. 不过在RTTF比较小的时候，预测的值都还不错。
13. 模型评估用的S-MAE，会忽略低于阈值的误差

# 面向Xen的软件故障注入方法研究与应用

**时间**：2017
**杂志**：南京理工硕士论文
**摘要**：

**关键词**：

## 总结

没看懂……总感觉没啥用
Ferrari[21】是美国德克萨斯大学奥斯汀分校研发的故障注入工具，是一种针对单机
环境下基于软件的故障注入工具。Xception[23]是一款商用软件，通过被测进程自
带的计数器和计时器触发故障注入，特点是实施故障注入不需要修改SUT。
FTAPE[22】实现了针对多种计算功能部件，如CPU、内存和IO等的故障注入，且
实现了多种故障模型，如针对CPU的故障模型有寄存器单粒子／多粒子翻转，寄
存器传值错误等。DOCTORC20]由美国密歇根大学研发，可以根据潜在的故障模
型或基于历史数据对系统进行故障注入。而且对分布式系统有较强支持。
DEFINE[19】由美国伊利诺伊大学开发，用来评估系统可靠性，故障传播及验证系
统容错性。DEFINE由FINE[18】扩展而成，对分布式系统有较强支持，相比于大
多数故障注入工具，其特点是较轻量。


# 软件故障注入关键技术研究

**时间**：2011
**杂志**：哈工大硕士论文
**摘要**：

**关键词**：

## 总结

也很复杂……
主要是想用于测试，不同测试阶段用了不同的注入方法，感觉没啥用

# Fault Injection Methodology and Tools故障注入方法和工具

北航17系

**时间**：2011
**杂志**：
**摘要**：
抽象
故障注入已被认为是评估计算机系统可靠性的强大技术。 本文介绍了故障注入的概念和原理。 详细介绍了几种故障注入技术及其工具。
故障注入； 依赖; 硬件故障注入； 软件故障注入； 基于VHDL的故障注入； 运行时重新配置

**关键词**：

## 总结

这大概就是传说中北航水的垃圾论文了。


a）由德克萨斯大学奥斯汀分校开发的Ferrari [1]使用软件陷阱来注入CPU，内存和总线故障。  
b）由密歇根大学开发的Doctor [9]允许注入CPU故障，内存故障和网络通信故障。 它使用上述所有三种触发方法来触发故障注入。  
c）Xception [10]是由葡萄牙科英布拉大学开发的，它利用了许多现代处理器中存在的高级调试和性能监视功能来注入更多实际的故障。 软件方法具有许多优点。  


# Emulation of Software Faults: A Field Data Study and a Practical Approach仿真软件故障：现场数据研究和实用方法

**时间**：2006
**杂志**：
**摘要**：

摘要—故障注入已被广泛用于评估容错机制并评估计算机系统中故障的影响。 然而，对软件故障的注入不像其他类型的故障（例如，硬件故障）那样好理解。在本文中，我们分析了如何以与源代码无关的方式注入（仿真）软件故障。 我们专门解决重要的仿真要求，例如故障代表性和仿真精度。 我们从分析大量实际软件故障开始。 我们观察到，很大一部分故障属于定义明确的类别，并且可以用非常精确的方式进行表征，从而可以通过一小组仿真操作员来精确地仿真软件故障。 提出了一种新的基于仿真算子的软件故障注入技术（G-SWFIT）。 该技术包括在机器代码级别上查找可以模拟高级软件故障的关键编程结构。 显示了该技术的故障仿真精度。 这项工作还包括对可能影响技术准确性的关键方面的研究。 还讨论了该技术的可移植性，结果表明可以实现高度的可移植性。

**关键词**：

Index Terms—Fault injection, software faults, software reliability.
索引词-故障注入，软件故障，软件可靠性。

 ## 1引言
 本文旨在模拟软件故障（即程序缺陷或错误），以达到软件可靠性和可靠性评估的目的。 多项研究表明，软件故障显然是计算机故障的根本原因[1]，[2]，[3]，[4]，并且鉴于当今软件的巨大复杂性，软件故障对整个系统可靠性的重要性 会增加。 在实践中很难完全消除软件开发过程中的软件缺陷。 除了软件开发和测试过程中众所周知的技术难题[5]，[6]之外，诸如缩短产品上市时间的巨大压力和软件成本之类的实际限制因素也导致难以保证100％的缺陷 -免费软件。 因此，计算机工业中的当前情况是，存在确实存在软件缺陷但没有人确切知道它们在哪里，何时会暴露出来以及最重要的是激活软件故障的可能后果的系统。 在当今越来越多使用现成组件（COTS）来构建大型系统的世界中，残留的软件故障代表着越来越大的风险。
   已经提出了许多软件可靠性模型和测量程序来预测和评估质量度量，例如给定软件包中剩余的故障数量。 但是，这是
   难以处理当今软件的极端复杂性，并且模型还必须考虑到诸如故障情况下的软件组件之间的交互以及现实的工作状况之类的方面，以便衡量残留故障对操作和维护的可能影响。 在最终用户上。
   在软件行业中，朝着面向组件的开发模型发展的明显趋势迫使软件供应商越来越多地考虑使用通用的通用组件（称为“现成组件” — COTS）。 这导致软件产品实际上是来自各种来源的小组件的集合。 在这种情况下，一个非常重要的问题是，当系统的一个组件（COTS或专门开发的组件）由于残留软件故障的激活而以错误的方式运行时，如何估计整个系统的行为。
   我们建议注入软件故障以帮助解决此问题。 在过去的二十年中，模拟硬件故障的故障注入技术已广泛用于评估特定的容错机制并评估系统中故障的影响。 然而，尽管已经认识到软件故障的注入可能非常有用[7]，[8]，但到目前为止，尚未提出以精确的方式在目标的可执行代码处注入残余软件故障的通用方法。
   除了要知道如何实际模拟软件故障这一主要问题外，还必须定义如何使用一种可能的技术来注入这种故障，因为它的使用不像模拟硬件故障的经典故障注入那样明显。  。 从一开始就建立一个用于注入软件故障的利用场景，对于帮助确定对软件故障的精确仿真提出的要求非常重要，这是我们研究的主要课题。
   在这种情况下，我们建议根据以下原则使用软件故障注入：
   注入给定的组件以评估存在该故障组件时整个系统的行为。
   这种情况的一个基本方面是目标组件（遭受故障注入的组件）和被观察系统之间的明确分离。 这是避免更改评估系统的问题所必需的，因为仿真软件故障将始终需要在目标代码中引入小的更改。 更具体地，所评估的是当其组件之一发生故障时的系统行为，而不是发生故障的组件本身的行为（见图1）。
   考虑到通常用于软件开发的基于组件的方法，软件组件的标识通常是由软件体系结构产生的。
   但是，可以根据需要确定用于定义软件组件的粒度，并且可以使用更详细的粒度。
   使用上面提出的场景（图1），我们确定了用于仿真软件故障的三种主要用途：

   图1.软件故障注入和系统观察。

1.容错机制的验证。 由于很少会触发已部署系统中典型的残留软件故障，因此可以通过仿真软件故障来加速软件故障激活，从而实现容错机制的验证[9]。
   2.最坏情况的预测和实验风险评估。 仿真软件故障可以用作一种从用户的角度量化软件故障影响的方法，并可以定量了解残留故障所代表的潜在风险。 通过执行风险评估和最坏情况的预测，这可以优化测试阶段的工作[8]。 例如，如果在给定组件中注入软件故障导致系统中发生灾难性故障的比例很高，则意味着该组件中残留的软件故障可能会带来很高的风险，因此应该在组件测试中投入更多的精力。 或应更改系统设计以减轻该特定组件中故障的影响。
   3.可靠性基准测试。 最近的一项研究工作集中在将可靠性基准定义为一种标准程序，以评估与存在故障的计算机系统或计算机组件的行为有关的措施[10]，[11]，[12]，[13]。  ，[14]，[15]，[16]。 技术技巧

模拟软件故障对于基准故障负载至关重要。
   众所周知，现有的故障注入技术可以使用简单的位翻转或卡住来模拟瞬态或永久性硬件故障。 但是，通过在目标可执行代码处进行故障注入来对剩余软件故障进行实际仿真要困难得多，并且仍然是一个相当晦涩的步骤。 实际上，模拟软件故障的问题本质上是困难的。 软件错误本质上是人为错误（在设计，实现等方面），因此很难对人为错误进行建模。
   围绕软件故障注入的关键问题是故障代表性。 理想情况下，注入的错误应该精确地模拟程序的隐藏缺陷，这显然是不可能的，因为这些缺陷不是事先已知的（如果我们知道这些错误，我们将事先对其进行修复）。 鉴于这种可能性，在实践中，通过错误注入对软件错误进行正确的仿真需要以下条件：

   1.识别和表征软件故障中最重要的类别，并估计实际程序中这些类别的相对百分比。 相关故障是属于已部署软件系统中发现的实际残留缺陷的代表性故障类型的那些故障。
   2.注入会产生错误或引起错误程序行为的故障的技术，类似于由特定类别的实际软件故障引起的故障。 也就是说，重要的是避免注入导致给定类别的软件故障无法生成的错误的故障。
   识别最可能的软件故障类别显然是最困难的问题。 原则上，可以通过使用有关开发过程的信息，开发软件的团队，代码的特定度量（代码大小，变量数量，数据结构的复杂性等）或有关先前故障的现场数据来实现此识别。 在程序中发现。 但是，考虑到所评估的系统/组件的源代码可能不可用（大多数COTS组件都是这种情况），不可能从开发团队/过程或以下方面的知识中获得足够的软件故障特征。 从代码复杂性指标中获取，当源代码不可用时，很难或无法获得这些指标。
   有关真实软件故障的现场数据可能是了解软件故障并帮助表征相关故障属性（例如每种故障类型的故障发生频率）的最重要资源。 不幸的是，关于真实软件故障的数据并不普遍可用，使用真实故障的研究工作很少见[2]，[4]，[17]，[18]。
   鉴于上述问题，本文以以下方式解决了故障代表性的关键问题以及注入软件故障的一般问题：1.提出了对大量实际软件故障（超过650个软件故障）的分析 ）。 故障源是一组用C语言编写的开源程序，包括应用程序和操作程序。

   系统代码。 对这些故障的详细分析为重要的故障属性提供了宝贵的见解，例如具有常见高级语言结构的故障关系以及程序执行中的故障影响。 这样可以更好地理解故障可能如何发生以及高级语言结构与特定故障类型之间的关系。 已根据观察到的一组故障收集了有关每种故障类型的故障发生的统计信息。 这些结果对于了解哪种故障类型代表残留故障很重要。
   2.提出对正交缺陷分类法（ODC）[19]，[27]的扩展，该分类法专门用于故障注入。 实际上，ODC已经成功地用作改进软件设计过程的工具，并为理解和分类软件故障提供了重要的基础。 但是，ODC将故障与纠正故障的方式联系在一起，而不是将其与可能的仿真方式联系起来。 鉴于可以用不同的方式纠正相同的故障，因此需要对故障的确切性质进行仔细研究以进行精确的故障仿真，这导致了新的故障分类，从而扩展了ODC在故障注入中的应用。
   3.介绍了技术G-SWFIT（通用软件故障注入技术），这是我们提出的用于注入软件故障的实用方法的建议。 该技术通过故障仿真操作程序库来仿真在现场最常观察到的软件故障类别，并将故障直接注入目标可执行代码中。 库中的每个故障仿真操作员都由一个机器代码级别的模式和相应的代码更改组成，这些代码更改表示在现场针对该代码模式最经常观察到的软件故障。
   从某种意义上说，我们的故障仿真运算符类似于用于突变测试的变异运算符[20]，[28]，[48]，[49]，但它们具有三个基本区别：1）我们的运算符直接在可执行代码中工作 而不是像突变的情况那样在高级源代码上，2）基于真实故障的现场观察，而不是像突变的情况那样是综合生成的，并且3）我们操作员的主要目标是模拟残差软件 而不是确定最佳的测试用例集，而软件突变通常是这样。
   4.通过比较此技术在机器代码级别上引入的故障的影响与相应的高级故障，来评估G-SWFIT的准确性。 通常，我们观察到注入的断层和应该模拟的实际断层之间的匹配度非常好。
   第4节介绍了这些结果，并使用假设检验来评估G-SWFIT注入的故障与在源代码级别插入的故障之间的相似性。
   5.从多个方面讨论所提出方法的一般性和可移植性，例如目标系统构建中使用的高级语言，编译器，编译器优化选项和处理器体系结构。 一个非常重要的结论是，G-SWFIT实际上独立于高级语言和编译器详细信息，这是在没有源代码的系统中使用该技术的必要条件。
   本文的结构如下：下一部分介绍了相关研究。 第3节介绍了现场数据软件故障的分析。 第4节介绍了G-SWFIT技术，并通过故障案例研究讨论了其准确性。 还解决了可移植性的重要问题。
   第5节提出了一些结论。