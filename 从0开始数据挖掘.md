# Part 1 赛题理解
1. 赛题
回归问题
给了哪些特征
和时间有没有关系，时间跨度有多大？
漂移？误报？异常值？
2. 赛制
3. 数据
显式特征（onehot编码 独立热编码
匿名特征（运算生成一些新的

数据范围，判断正常异常
数据样本有多大

理解评测标准

结果提交
注意格式，列名

常见评价指标：
分类：
二分类：acc，precision，recall，F-score，Pr曲线，ROC-AUC曲线
多分类：acc，宏平均和微平均，F-score
回归：
MAE，MSE，MAPE，R2

xgb，lgb，catboost

指标：sklearn.metrics

赛题理解究竟是理解什么：
什么样的问题
有了赛题理解后能做什么：
数据读取，看分布
赛题背景中可能潜在隐藏的条件
缺失，漂移，异常，背后的逻辑


Baseline

## 了解赛题类型
是回归、分类、还是其他

赛题背景可能会潜在一些隐藏条件，对之后的数据处理可能会有帮助
如是否包含异常值，缺失、漂移
是否会包含多种情况，这时需要注意模型的泛华性
高效性，比如工序流程的差异性，比如模型运行的时间、模型的鲁棒性
## 数据理解
### 字段含义
明确的特征：分类、连续、变量间的交互
匿名特征：四则运算、取log、统计指标
### 数据量
观察数据量以了解需要电脑配置的情况
### 评测标准
回归常用标准：MAE、MSE、R^2
线下验证的时候模型评价指标和线上保持统一
不同指标带来的差异效果是不一样的
### 结果提交
关注细节，是否需要列名等等
## 分析赛题
### 经验
数据比赛一般常用的模型：XGB，LGBM
sklearn是入门数据比赛一个很好的包，可以重点学习
### 回归问题
数据分析，特征的构建
选用好的模型
### 代码分析
用pandas读取数据
各类指标可以用sklearn，metrics包去构建
## baseline讲解
### 大佬的比赛流程
1. 先写一个baseline调教
2. 在baseline的基础上做优化：数据处理、特征处理、模型调参
3. 模型融合
### 读取数据、数据统计信息
info(),head()
describe()统计信息
对比train和test的情况：是否统计信息相近，详尽说明分布一致，模型效果稳定，如果分布不一致的话，需要对train做一些采样等处理，使两者分布接近
### 特征的类型
数值型、分类型
### 标签的分布
原理上来说，train和test的概率分布应该是一致的
### 模型构建
1. XGB LGB函数
2. param_grid网格调参
3. 切分数据集：train：validation = 7:3    4:1
4. 对比不同模型的结果解读：
  1. 对比均值 方差
  2. 将预测结果和train data对比，是否统计指标接近，是否有特殊的点需要关注处理
  3. 结合实际含义，比如最小值是负数
5. 不同模型的结果加权

# Part 2 EDA
## EDA要做什么
+ 数据大致表达了什么
+ 挖掘数据结构：结构化、图像等
+ 初步分离出一些重要特征
+ 挖掘离群数据和异常数据
+ 初步确定可以用哪些模型
## 绘图方法
+ 时序图：变化规律
+ 直方图：分布
+ 密度曲线：分布
+ 箱型图：查看数据异常状况。不同数据间分布的对比
+ 小提琴图：进阶版箱型图。某个值附近的概率分布
## 量化方法
### 相关性分析
+ 定类变量：性别
+ 定序变量：教育程度
+ 定距变量：价格

|      | 定类       | 定序                              | 定距             |
| ---- | ---------- | --------------------------------- | ---------------- |
| 定类 | 卡方类测量 | 卡方类测量                        | Eta系数          |
| 定序 |            | Spearman相关系数、同序-异序对测量 | Spearman相关系数 |
| 定距 |            |                                   | Pearson相关系数  |

### 独立性分析
变量间无线性相关性，还可能存在非线性关联
MV test独立性检验

# 特征工程
## 数据理解
## 数据清洗
1. 特征变换
2. 缺失值处理
3. 异常值处理
4. 其他
## 特征构造
增强数据表达，添加先验知识
1. 统计量特征
2. 时间特征
3. 地理信息
4. 非线性变换
5. 数据分桶
6. 特征组合	
## 特征选择
1. 过滤式
2. 包裹式
3. 嵌入式
## 类别不平衡
1. 扩充数据集
2. 尝试其他指标
3. 调整θ值
4. 重采样
5. 合成样本
6. 选择其他模型
7. 加权
8. 创新：
  1. 大类分解
  2. 小类视为异常点

# 建模和调参
## 基础知识
### 统计学习分类
1. 监督学习
2. 非监督学习
3. 半监督学习
4. 强化学习
### 常见的监督学习模型
1. 线性模型
2. 决策树
3. 神经网络
4. 支持向量机
5. 贝叶斯分类
6. 集成学习模型
### 基本概念
模型、策略与算法
评价函数
目标函数
过拟合与欠拟合
正则化
交叉验证
泛化能力
### 验证方法
训练集、线下验证集、线下测试集、线上测试集
无时序的数据集：简单划分、交叉验证划分等
有时序的数据集：需考虑时序，nested交叉验证划分等
### 注意
模型选择
依据在验证集上的效果选择
除了关注效果的均值，还要关注稳健性
还需考虑线上效果；可将线上效果视为一折数据

参数调优
不建议将精力放在参数调优上；容易过拟合
大体的设置参数即可
应将精力重点放在特征工程；其次是模型融合
