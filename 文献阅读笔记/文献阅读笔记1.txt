
# 模板



**时间**：
**杂志**：
**摘要**：

**关键词**：

# Software Reliability Engineering - A Review软件可靠性工程-回顾
软件可靠性工程-回顾

**时间**：2011年9月
**杂志**：International Journal of Applied Physics and Mathematics
**摘要**：
略
**关键词**：
reliability， waterfall ，prototyping ，incremental，rapid，evolutionary，agile
可靠性，瀑布模型，原型制作，增加的，快速，进化，敏捷

## 总结

1. 里面有传统可靠性的浴盆曲线和理想化的软件可靠性曲线。
2. 有常见的软件开发模型的简介，有瀑布模型、原型制作、增量开发、螺旋发展、快速应用开发（RAD）、进化发展方法、Rational统一过程、基于组件的软件开发。
3. 有计算机辅助软件工程、IDE、敏捷开发（极限编程XP、Scrum）的简介。
4. 至于文章本身提出的那个东西，就是说要先建模算一算可靠性，直接算可能有困难。但是啥有用的东西都没有。

# Deterministic Models of Software Aging and Optimal Rejuvenation Schedules软件老化和最佳复兴计划的确定性模型
软件老化和最佳复兴计划的确定性模型

**时间**：2007
**杂志**：
**摘要**：
研究对象：服务器Axis Soap Server 1.3
对老化建模，从而进行Rejuvenation。SLA约束、

建模算法：样条插值拟合
**关键词**：

## 总结

1. 在介绍中提到了老化、Rejuvenation的介绍，两种基本的Rejuvenation思路：定时，积极（根据建模）。
2. 用某些指标来评价老化：服务器每秒可处理的最大请求数。
3. 假设性能下降与负载有关的函数。假设模型可以足够精确的建模。
4. 介绍了建模思路：分析建模和基于度量建模
5. 建模过程：分段用样条拟合
6. 假设老化指标只取决于单个负载指标。或者多个负载指标的简单函数。
7. 用方差分析进行了模型验证
8. 改进了方差分析法，引入了方差容忍度
9. 分析了如何得出最佳Rejuvenation的时间，此处没有细看
10. 实验通过10台客户端连接1台服务器来注入负载。
11. 收集的系统参数有：
  + free memory：available memory in the JVM of the SOAP
server
  + cpu_user： % of CPU time used by the user applications,
  + cpu_system：操作系统使用的CPU时间的百分比，
  + cpu_idle：CPU空闲的时间的百分比，
  + request_per_sec：SOAP服务器的吞吐量，以每秒执行的请求数为单位，
  + min_lat：请求延迟最小观测值
  + maxlat：请求延迟最大观测值
  + avg lat：请求延迟平均值。
12. 实验方法：以超过服务器容量的某一个固定值持续加压
13. 老化指标：每秒请求数。负载指标：经选择，用了自上次重启以来的请求数。
14. 图像的曲线都是很平滑的，先上升，然后缓慢单调下降的样子。【随着总请求数越来越多，每秒的请求就越小，老化了。】

# Basic Concepts and Taxonomy of Dependable and Secure Computing可靠和安全计算的基本概念和分类
可靠和安全计算的基本概念和分类

这篇好像是大佬的综述
**时间**：2004
**杂志**：IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 1, NO. 1, JANUARY-MARCH 2004 
**摘要**：
就是各种定义。
**关键词**：
Dependability, security, trust, faults, errors, failures, vulnerabilities, attacks, fault tolerance, fault removal, fault forecasting
可靠性，安全性，信任性，故障，错误，故障，漏洞，攻击，容错，故障消除，故障预测
## 总结

非常详尽的定义

# Detecting Application-Level Failures in Component-Based Internet Services在基于组件的Internet服务中检测应用程序级故障
在基于组件的Internet服务中检测应用程序级故障

作者一个是斯坦福的，一个是MIT的
**时间**：2005
**杂志**：IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 16, NO. 5, SEPTEMBER 2005 
**摘要**：
大多数Internet服务（电子商务，搜索引擎等）都存在故障。
快速检测这些故障可能是提高系统可用性的最大瓶颈。
我们介绍方法Pinpoint，一种通过以下方法在Internet服务中自动进行故障检测的方法：1）观察服务的底层内部结构行为； 2）将系统的多数行为建模为正确； 3）将这些行为中的异常检测为故障的可能症状。
不需要任何先验的特定于应用程序的信息，Pinpoint在我们的实验中正确地检测出了89％–96％的重大故障，与此同时，当前的通用应用技术检测出了20％–70％。
**关键词**：
Anomaly detection, application-level failures, Internet services.
异常检测，应用程序级别的故障，Internet服务。

## 总结

1. 研究的是应用程序级的故障：会影响用户可见的一些功能，但是不会引起系统崩溃一类的运营商可检测到的系统级故障
2. 无需先验信息，对正常状态进行建模。
3. 监控内部组件的trace形状：客户请求后经过的部件名称。监控部件之间的交互情况。
4. 实验对象：J2EE应用程序
5. 主要关注在故障发生后尽快检测到
6. 监测方法：写在了J2EE上
7. 故障注入研究，参考文献4,18-21，列举了一部分，没有详细步骤
8. 计算P的时候通过min(0, score-a)过滤掉大于a的一些值
9. 组件交互的计数与请求路径分析有一定程度上的互补。
10. 用PCFG对路径进行了建模，从这里就与我的研究无关了。
11. 本篇有简略译文。


# A Measurement-Based Model for Estimation of Resource Exhaustion in Operational Software Systems基于测量的运营软件系统资源枯竭估计模型
基于测量的运营软件系统资源枯竭估计模型

**时间**：1999
**杂志**：
**摘要**：

主要研究软件老化。本文考虑了系统的工作负荷，函数的自变量之一。本文提出了一个基于度量的模型，来估计操作系统资源的耗尽率，自变量为时间和工作负载状态。用基于Unix系统收集到的工作量和资源使用情况构建了半马尔科夫奖励模型。先用统计聚类分析对工作量的状态进行了聚类，然后根据每种在不同状态下的资源枯竭率，为该模型定义奖励函数。然后求解该模型以获得**趋势**以及资源的估计**耗尽率**和**耗尽时间**。


**关键词**：

## 总结

1. 研究老化，主要原因：操作系统资源的耗尽，数据损坏和数字错误累积。导致系统崩溃或挂起。
2. 常见情况：**内存膨胀和泄漏**，**未释放的文件锁**，数据损坏，存储空间碎片以及舍入错误的累积
3. 预测资源消耗的时候考虑了工作负载。
4. 相关工作中提到：
   1. 时间为变量预测系统资源的方法
   2. 有一些文献说明了资源、负载与失效的相关性。
   3. 别的工作负载指标：CPU使用率、内存使用率
   4. 性能的单词用了performability
5. 马尔科夫不太懂，没有细看。简单的说，应该是预测一个状态到另一个状态转换的概率。
6. 10分钟一次，监控了3个月：系统资源状态、进程状态、文件系统信息【/tmp】、网络相关、磁盘IO，共100多个此类参数【和sar的差不多，只不过多了进程信息？】
7. 要预测的值：usedSwapSpace和realMemoryFree。建模用的数据是最长的采样时间内的数据【重启或发生了故障则重新采样】
8. 工作负载的表示：工作负载与CPU和I/O有关，故采用cpuContextSwitch【测量间隔内，进程的上下文切换数量】、sysCall【系统调用数】、pageIn【从文件系统或交换设备分页的页面数，就叫page-in】、pageOut
9. 对于每个工作负载的点【相当于一个四维空间的点】进行聚类，算法用的Hartigan【一种k-means聚类算法】。聚类发现一些状态时轻量工作状态，一些是高负载。
10. 计算状态转移概率【通过简单除法】，构建转移矩阵。半马尔科夫好像还要状态持续时间，反正根据分布大概定了一个？然后验证了一下结果，效果很不错。
11. 这里有点看不懂了，反正是通过奖励函数，利用半马尔科夫模型对要预测的两个值进行了预测
12. 计算斜率的方法[20]：这个斜率好像是大量样本的总斜率，跟我要的不一样。
13. 最后这个结果有点迷，看不懂


# A Best Practice Guide to Resource Forecasting for Computing Systems计算系统资源预测的最佳实践指南
计算系统资源预测的最佳实践指南

**时间**：2007
**杂志**：
**摘要**：
在本文中，我们基于预测Apache Web服务器性能变量以及预测实际电信系统的呼叫可用性的经验，提出了建立经验模型的最佳实践指南。为了证实所提供的指南，并逐步演示我们的方法，我们对**响应时间**，Apache Web服务器系统的**可用物理内存**量以及工业电信系统的呼叫call可用性进行建模和预测。此外，我们为a）基准交叉验证三个**变量选择**的方法，b）基准交叉验证四个**经验模型构建**的方法以及c）**敏感性分析**  提供了具体的结果。本最佳实践指南旨在协助系统地配置建模方法，以实现最佳估计和预测结果。

**关键词**：
Apache web server, failure forecasting, monitoring,
non-parametric modeling, prediction of resource utilization,
quantitative analysis, statistical modeling, telecommunication
systems.

Apache Web服务器，故障预测，监视，非参数​​建模，资源利用预测，定量分析，统计建模，电信系统。

## 总结

1. 本篇文献非常有用，基本上阐述了在当时的常用方法，并进行了总结，还有完整的实验和分析
2. Introduction里的很多也非常有用，可以直接用
3. 补丁、更新会把测试过的系统编程未测试的系统，引入新的错误，所以需要预测
4. 预测了Apache服务器中的响应时间和可用物理内存。电信系统的那个例子没细看。
5. 主要过程：数据选择【向前选择，向后消除，PWA概率包装】，建模【**多元线性回归、UBF、RBF、SVM**】，敏感性分析【删除一个看看模型的指标怎么样，后来发现敏感性与目标值的相关性关系不大】
6. 选择好的数据子集要比选模型重要的多
7. 介绍了大量之前别人用过的模型，文献
8. 数据集分成了三份，【按时间分的？从图上看是这样的】将第一段用于参数化模型，第二部分对模型进行交叉验证并限制过度拟合，第三部分用于对模型的泛化性能进行评估。一二段都喂给模型
9. 数据有峰值，处理方法：一段时间窗口内的中位数median，感觉平均值也行？或者就是平均值？
10. 数据：系统变量一类的和网络相关的，还有一阶导数
11. 响应时间预计：
    1. 实际数据：整体缓慢上升，有非常多的峰值，整体是个锯齿
    2. 中位数处理后，整体单调上升，最后一段略微下降一点点就平了
    3. 大概每6h有一次峰值
    4. 短期预计选出来的变量有：
       1. 新进程数
       2. 硬盘写入块数
       3. eh0_trans_pkts
       4. lo_recv_pkts
       5. SwapOutCounter
       6. si_slab_cache
       7. si_size_256
       8. ContextSwitches的导数
       9. CachedMemory的导数
    5. 长期的变量有：
       1. 新进程数
       2. eh0_recv_pkts
       3. ContextSwitches
       4. TimeIdelMode
       5. io_trans_bytes
       6. SwapInCounter
       7. si_size_256
       8. si_size_32
       9. ContextSwitches的导数
12. 可用内存预计
    1. 数据趋势：先下降，然后到一个地方后开始上升
    2. 变量有：
       1. t-1时刻的可用物理内存
       2. TimeUserMode
       3. 新进程数的导数
       4. si_files_cache

# Quantifying Temporal and Spatial Correlation of Failure Events for Proactive Management量化故障事件的时间和空间相关性以进行主动管理

量化故障事件的时间和空间相关性以进行主动管理

**时间**：2007
**杂志**：
**摘要**：

故障事件在时空方面表现出很强的相关性。 在本文中，我们开发了具有可调时标参数的**球形协方差模型**以量化时间相关性，并建立了随机模型以表征空间相关性。 进一步扩展了模型，以考虑到应用程序分配的信息，以发现故障实例之间的更多关联。 我们根据故障事件的相关性对它们进行聚类，并预测其未来的发生。
在生产联盟系统Wayne State Grid上的实验结果表明，我们的预测系统进行的离线和在线预测可以预测72.7％至85.3％的故障发生，并捕获集群联盟环境中的故障相关性。

**关键词**：

## 总结
1. 主要考虑的是故障之间的时间相关性和空间相关性
2. 时间相关性：a.短时间内多个节点同时发生一个故障；b.故障在解决前多次出现
3. 空间相关性：a.故障几乎同时发生在多个节点上【一个程序要用多个节点，有bug都得坏】；b.节点故障会导致别的节点的另一种故障【一个坏了会传错误数据】
4. 实验对象，他们学校的一个计算集群，最小单位就是一台计算机……
5. 收集的信息：失效签名：内存、CPU、I/O、包
6. 聚类算法？
7. 失效是个重尾分布，而且软件故障最严重（相比于硬件和全部）
8. 时间相关性：用时间差衡量距离，定义了一个球形协方差矩阵【没看懂】
9. 空间相关性：主要是计算失效数，拿概率算的。
10. 离线预计算法4+1：MEAN：以先前度量的平均值作为预测；  LAST：使用最后一个度量；  AVE（n）：使用最近n个小节的平均值；  AR（m）：是自回归的； 一种人工神经网络算法NN（n），使用最后n个数据来更新神经网络并预测故障【3个隐藏层】。
11. 在线预计：拿0~t的数据来预测，然后对比t~T的结果。

# Online Reliability Prediction via Motifs-Based Dynamic Bayesian Networks for Service-Oriented Systems面向服务的系统通过基于Motifs的动态贝叶斯网络进行在线可靠性预测
面向服务的系统通过基于Motifs的动态贝叶斯网络进行在线可靠性预测


**时间**：2016
**杂志**：IEEE Transactions on Software Engineering
**摘要**：

面向服务的系统系统（SoS）将系统视为服务，并通过服务组合技术外包外部组件系统来构建健壮的增值SoS。 为了应对在动态和不确定的运行环境下运行的松耦合SoS，为确保整体服务质量（QoS）的目的而对组件系统进行在线可靠性预测通常是一个重大挑战。 这也是通过优化服务选择以确保可靠的系统构建来保证SoS的运行时QoS的前提。 我们为面向服务的SoS中的组件系统提出了一种新颖的在线可靠性时间序列预测方法。 我们利用概率图形模型（PGM）来产生接近未来的时间序列预测。 我们通过从广泛使用的真实Web服务中收集的调用记录来评估该方法。 实验结果证实了该方法的有效性。


**关键词**：Index Terms—Online reliability prediction, time series, service-oriented computing, system of systems

索引词-在线可靠性预测，时间序列，面向服务的计算，系统系统

## 总结

1. 本文没有详细阅读
2. 主要是针对System of Systems，好像会有一些独特的问题，本文重点在预测可靠性
3. 在线可靠性时间序列预测
4. 历史参数：响应时间，吞吐量，可靠性，用概率图像模型PGM分析。对历史参数预处理，分成等长的时间序列。然后用主题的概念来描述时间序列的模式。然后用马尔科夫表达序列间的关系，生成条件概率表CPT，CPT与PGM一起用于预测。主要是基于动态贝叶斯网络，整合了时间序列。
5. 论文15中有简要介绍





# Seer: A Lightweight Online Failure Prediction Approach 一种轻量级的在线故障预测方法
Seer：一种轻量级的在线故障预测方法

**时间**：2017
**杂志**：IEEE Transactions on Software Engineering
**摘要**：

**关键词**：

## 总结
1. 从程序内部收集信息会产生过多的运行时开销，所以现有方法通常会避免使用
2. Seer是通过硬件性能计数器（HPC）来收集数据的，在硬件层面收集数据，如CPU驻留计数器来收集执行的指令数和采取的分支数量
3. 与此同时还可以结合系统层次收集到的进程数、CPU、内存、网络利用率来加强预测效果。【这个他好像没做，看了眼图，确实没有】
4. 现在大部分的预测都是把软件当黑盒子，可以考虑白盒拿到更内部的数据。不这么做的主要问题是开销太大。
5. 本文未精读。
6. 先把历史数据输入，然后选出一些可以在运行时监控的函数，然后从这些函数的历史数据里收集信息，用于识别出一些候选函数。然后再在候选函数里选，选出seer函数，用seer函数预测。
7. 过滤历史数据：1. 过滤掉error级别的，因为这时候已经发生了，该函数对预测没啥用。2. 过滤掉执行次数太多的，考虑开销
8. 筛选变量：对每一个函数都构建了一个决策树，然后把F值高的留了下来
9. 滑动窗口：函数做出的一系列的预测用于分析。背后可能的原理[34]：程序中的缺陷会不断地传播，感染更多的程序状态，那么一段时间内的一系列预测可以提高预测准确性。随着时间流逝，与正常值的偏差可能增加。
10. 每个seer函数在调用后都会给个预测值，T或F，一个执行的所有预测值叫health index
11. 滑动窗口是用每个seer函数的最后l个预测值去预测会不会失效。然后把窗口内的分数做个加和这样。
12. 感觉很有趣的东西，没时间细看了。
13. TOT_INS计算执行的机器指令的数量。BRN_TKN计算采取的分支数。LST_INS对执行的加载和存储存储器指令的数量进行计数。

# DAC-Hmm: detecting anomaly in cloud systems with hidden Markov models
DAC-Hmm：使用隐藏的马尔可夫模型检测云系统中的异常


**时间**：2015
**杂志**：
**摘要**：
云计算系统的异常检测解决方案必须在运行时运行，而且不需要事先了解正常或异常行为。 本文提出了一种基于隐马尔可夫模型的无监督在线异常检测方案。 我们的算法基本上是分布式的，并在云上的每台计算机上本地运行，以实现高可扩展性。 在真实数据集上进行的实验证实了以下事实，即我们的算法可以为一系列系统异常实现高检测精度，而对云基础架构的开销却很小。 
**关键词**：

## 总结
我感觉这个跟我没啥关系，云计算，黑盒的，而且还是无监督异常检测，不是预计

# The Time Dimension in Predicting Failures: a Case Study预测故障的时间维度：一个案例研究

**时间**：2013
**杂志**：
**摘要**：

**关键词**：
## 总结
1. 这篇文章复制不了，好坑
2. 时间窗口

# Fundamental Concepts of Dependability

**时间**：2001
**杂志**：
**摘要**：

**关键词**：

## 总结
和可靠性，故障，失效有关的一些概念。

# A Survey of Online Failure Prediction Methods
重要！！！

**时间**：
**杂志**：
**摘要**：

**关键词**：

本文有目前的方法分类，还有一个大表格，非常有用，之后整理出来。



# A Survey of Software Aging and Rejuvenation Studies软件老化和复兴研究概述

**时间**：
**杂志**：
**摘要**：

**关键词**：

## 总结
1. 预测值与真实值的差是不是也可以用，有文章用此作为了开始老化的起点现象。 
2. 记得考虑负载的问题。

# Towards assessing representativeness of fault injection-generated Failure Data for Online Failure Prediction面向评估故障注入生成的故障数据的代表性，以进行在线故障预测

**时间**：2015
**杂志**：
**摘要**：

**关键词**：

注入的软件故障是否有代表性是最后生成的故障数据有效的一个必要条件。生成的故障相关的数据的代表性依旧是个仍未解决的问题。在这项工作中，我们提出了使用G-SWFIT逼真的软件故障注入技术来评估故障相关数据的代表性的初步研究。我们在这里解决代表性估计和评估的概念和度量标准的定义。

## 总结

1. 主要研究的是软件注入的故障是否有代表性的问题。
2. 提到了G-SWIFT：通用软件故障注入技术。Time Domain那篇文章也是用的这个。



   [11] J. A. Duraes and H. S. Madeira, “Emulation of software faults: A
field data study and a practical approach,” IEEE Trans. Softw. Eng.,
pp. 849–867, 2006.

   

![image-20200528120319033](C:\Users\55012\AppData\Roaming\Typora\typora-user-images\image-20200528120319033.png)

![image-20200528120331247](C:\Users\55012\AppData\Roaming\Typora\typora-user-images\image-20200528120331247.png)


# A Machine Learning-based Framework for Building Application Failure Prediction Models基于机器学习的框架，用于构建应用程序故障预测模型
基于机器学习的框架，用于构建应用程序故障预测模型

**时间**：2015
**杂志**：
**摘要**：

摘要—在本文中，我们提出了构建故障预测模型的框架（F2 PM），这是一个基于机器学习的框架，用于构建用于在存在软件异常的情况下预测应用程序的剩余故障时间（RTTF）的模型。
   F2 PM使用对许多系统功能的测量来创建知识库，然后将其用于构建预测模型。
   F2 PM与应用程序无关，即    它仅利用对系统级功能的度量。 因此，它可以在不同的上下文中使用，而无需对运行中的应用程序进行任何手动修改或干预。
   为了生成优化的模型，F2​​ PM可以执行功能选择，以在所有测得的系统功能中识别对RTTF的预测有重大影响的功能。 这样可以产生使用不同输入功能集的不同模型。 用户可以使用F2 PM生成的一组度量来比较生成的模型，这些度量与模型预测准确性以及模型构建时间有关。
   我们还展示了使用标准TPC-W电子商务基准成功应用F2 PM的实验结果。


**关键词**：

## 一，引言
在计算系统中，可用性和性能下降的一个重要原因是不同性质异常的积累。 这些异常的很大一部分通常与错误和/或应用程序的次佳实现有关，这可能导致发生例如内存泄漏，未终止的线程，未释放的锁，文件碎片。 这些现象已在不同情况下得到了广泛观察，发现平均百分比为40％的异常是由于软件开发中的错误所致[1]。 随着时间的推移，这些异常的累积会导致系统资源耗尽，并可能导致性能的增量损失，甚至导致主机系统挂起/崩溃。 对于长时间运行的应用程序（例如，许多托管在Web /应用程序服务器中的应用程序），资源耗尽的影响会得到特别增强，随着时间的推移，资源消耗的后果可能会累积大量异常。 在大多数情况下，应用程序中异常的发生是不可预测的，并且其原因很复杂。 此外，在某些情况下，要找出原因，就需要付出巨大的努力，甚至可能会导致成本低效。 在这些情况下，首选解决异常累积的替代方法，例如执行旨在消除其影响的适当纠正措施。 例如，一种广泛采用的技术是软件复兴[2]，它包括将应用程序/系统的状态强制为“干净”状态，即已知该系统/应用程序在不存在（或不存在）的情况下工作的状态。 减少的数量）。 典型动作
清理状态包括重新启动应用程序或重新启动系统。
   通常，能够预测异常的发生（以及与异常累积有关的影响）可以帮助改善系统的性能和可用性。 实际上，可以预先执行适当的操作，以防止即将发生的系统故障或过度的性​​能下降。 在软件恢复的情况下，这种主动方法称为主动恢复，它包括在预计会发生崩溃的时间之前，预防性地将应用程序或主机系统强制进入干净状态。
   在本文中，我们介绍了构建故障预测模型的框架（F2 PM），这是一种基于机器学习（ML）的框架，旨在构建系统故障预测模型。
   F2 PM允许生成优化的ML模型，以预测何时会发生给定的（异常）情况。 我们通常将此时间称为“剩余故障时间”（RTTF）。 该条件可以识别不同类型的系统故障。 具体而言，它可以由用户根据一个或多个选定系统特征的值进行定义，这可以揭示系统正在接近（例如，悬挂点或崩溃点）或以次优方式工作（例如，  ，它提供的性能非常低）。
   F2 PM以非介入方式运行，即不需要任何类型的应用程序工具（例如插入用于收集数据的探针），因此完全与应用程序无关。 实际上，F2 PM仅利用系统级功能，可以通过使用通常也包含在所有常见操作系统的基本版本中的简单工具来监视这些功能。 这使得F2 PM具有通用性。 由于我们的建议是基于机器学习技术的，因此它的适用范围适用于所有可能预先收集足够数量的监视现象观测值的情况。 本质上，受监视系统中异常/故障的发生率越高，可靠预测模型（与受监视系统一致）的生成就越快。
   F2 PM依赖于初步的系统观察阶段。
   在此阶段中，将监视许多系统功能并记录其值，同时负责生成异常的应用程序将运行。 每次满足用户定义的条件时，F2 PM记录发生时间，然后重新启动系统。 然后，将收集的数据用于构建和验证使用不同ML算法生成的多个模型。 在建立模型之前，F2 PM还执行两个附加步骤：1）根据收集的系统计算得出的多个衍生指标的值
   将特征添加到收集的数据中； 2）执行数据选择步骤，在该步骤中，从数据集中提取许多训练集（包括特征和度量的不同子集）。 然后，通过将ML算法应用于不同的训练集来生成许多模型。 对于每个模型，F2​​ PM提供了一组测量准确性和模型训练/验证时间的度量，从而为用户提供了基于模型准确性和构建时间选择最适合模型的可能性。 特别是，该组度量还包括软均值绝对误差（S-MAE），它在假定低于给定用户定义阈值T的误差可接受的情况下（即小于T的误差不可接受）评估绝对预测误差 在评估指标时考虑）。 在对系统故障进行主动管理时，S-MAE特别有用。 实际上，在这种情况下，如果在预测系统出现故障之前的时间T处执行了校正操作，则将容忍小于T的预测误差。
   我们还将展示在Web应用程序中如何实例化F2 PM。 但是，我们注意到F2 PM旨在独立于特定类型的应用程序和异常类型使用。 实际上，通过更改观察到的系统功能集并定义将系统视为故障所要满足的适当条件，可以为不同的系统和应用定制F2 PM。
   最后，为了强调F2 PM的有用性，我们注意到在使用虚拟化技术时，软件更新已被证明是一种有效的技术[3]。 鉴于虚拟化和云计算架构的广泛采用，这极大地扩展了F2 PM的使用范围。
   本文的其余部分的结构如下。 在第二节中，我们讨论相关工作。 第三部分描述了F2 PM的组织以及其开发背后的设计原则。 最后，在第四部分中，我们介绍并讨论了在Web应用程序中使用F2 PM收集的实验结果，其中使用了托管在Apache Tomcat之上的TPC-W基准测试[4]的实现。
   ## 二。 相关工作
   预测应用程序异常的影响并不是一个新主意。 沿着这条道路，已经有几项工作提出了预测技术和模型[5]。
   在[6]中，作者提出了一个针对大型集群的主动预测和控制系统。 该提案依赖于包含六类事件的日志，这些事件分为几类（例如    大型系统（350个节点）的一年活动期间收集的特定系统的可用性或性能违规阈值。 通过使用时间序列，基于规则的分类和贝叶斯网络，作者可以过滤初始数据，仅选择条目，这对于进行预测很有用。 从本质上讲，与上述工作相反，本文设计了一个框架，该框架能够自主导出一组不同的预测模型，从而使用户能够选择最适合的模型。
   在[7]中提出了一种自动检测异常并跟踪应用程序性能的框架。 该框架依赖于基于回归的交易模型，
   它反映了应用程序的资源消耗模型。
   该建议明确监视每个事务的CPU使用率，因此需要对应用程序进行更深入的分析。 与F2 PM的主要区别在于，它不需要在应用程序中插入任何种类的探针，从而极大地简化了其实例化广告的使用。
   在[8]中，提出了一种在预测即将到来的崩溃时支持虚拟化系统恢复活力的框架。
   该框架具有我们共同的一些特征，包括基于套索正则化的派生指标计算和特征选择。 无论如何，还是有很大的差异。 在[8]中的框架中，决策规则是在运行时生成的，以支持软件更新。
   相反，F2 PM能够产生不同的ML模型，包括非线性模型，其训练是从不同的（过滤或未过滤的）训练数据集开始进行的。
   因此，正如我们在第一节中讨论的那样，F2 PM使用户能够比较不同的模型并根据一组度量标准选择最佳模型。此外，[8]中框架生成的预测模型仅使用 在系统中注入了合成异常，并且仅在内存泄漏的情况下。 取而代之的是，我们展示了F2 PM在结合不同异常率（也以不同比率发生）的情况下是有效的，并且我们在实际应用中展示了F2 PM。
   有一套商业工具[9]，[10]，[11]，可通过检测JVM来监视Java应用程序。 尽管这允许非侵入式工具通过重建交易的执行路径来分析交易的绩效，但这种方法是非通用的，因为它只针对基于Java的应用程序。 当我们以与应用程序无关的方式进行操作时，我们保留了监视此类应用程序演变的能力，同时将应用程序范围扩展到了用于构建（虚拟化）服务的任何语言。
   在精神上与我们在此展示的类似，是在[12]中的工作，其中提出了一组针对软件异常的著名机器学习分类器的评估。 在[12]中，定义了软件系统生命的三种不同状态（都正常，警告和危险），并且生成的模型仅能够预测系统当前期望处于哪种状态。 不同地，我们能够生成模型以精确估计RTTF。
   
   ## 三，  F2 PM框架
   F2 PM旨在构建优化的ML模型，以预测系统故障的发生。 模型接收所选系统功能集的值作为输入，并提供RTTF，其中故障条件由用户定义。
   F2 PM基于图1所示的工作流。为简单起见，在我们的演示中，我们以通用Web应用程序为例，在该示例中，我们假定内存泄漏和未终止的线程可能在整个生命周期中以不同的速率发生。 应用程序。 但是，正如我们在第一部分中讨论的那样，F2 PM不限于此类应用程序和此类异常。 在下文中，我们将通过一系列阶段来描述F2 PM的工作流程，以进行详细介绍。
   
   ### A.初始系统监控
   如第一节中所建议，初始系统监视阶段包括在系统运行生成异常的应用程序时收集许多系统功能的度量。 定期测量所有受监视的系统功能，并由用户确定间隔。 每个测量（数据点）都带有从系统启动起经过的时间的时间戳。 因此，F2 PM将创建一个数据历史记录，包括所有数据点的顺序。 每次满足系统故障条件时，都会将故障事件添加到数据历史记录中，然后重新启动系统。 这引起了系统的许多运行。 我们注意到，对于不同的系统，此阶段的持续时间可能会非常不同，这主要取决于异常发生率和系统中可用资源的数量。 特别是，必须收集足以建立具有给定精度的ML模型的给定数据量。 确定此阶段要收集的数据集的大小可能需要很长的训练时间。
   F2 PM可以通过允许用户评估所生成模型的准确性的一组指标来逐步支持此任务。 如果估计的准确性不足，则可以执行进一步的系统运行，以将新数据收集到训练集中，并生成新模型。
   每个数据点都由一个元组组成，该元组包含以下一组值：
   
   Tgen是表示自系统启动以来经过的时间的时间戳。  nth是系统中活动线程的数量；  Mused是系统中运行的应用程序使用的内存量；  Mfree是可供应用程序免费使用的内存量；  Msharedis用于应用程序共享的缓冲区的内存量；  Mbuff是底层操作系统用于缓冲数据的内存量；  Mcached是用于缓存磁盘数据的内存量；  SWused是当前使用的交换空间量；  SWfree是交换空间的数量，当前可用；  CP Uus是专用于用户空间进程的CPU时间的百分比；  CP Uni是具有正尼斯值（较低的调度优先级）的用户级进程占用的CPU时间的百分比；  CP Usysis在内核模式下花费的CPU时间的百分比；  CP Uiowis等待I / O操作完成所花费的CPU时间的百分比；  CP Ust是虚拟机管理程序为另一个虚拟处理器提供服务时，虚拟CPU等待实际CPU的时间百分比。  CP Uid是完成无效工作（即系统负载不足）所花费的CPU时间的百分比。
   
   
 我们注意到我们选择上面列出的系统功能是因为，基于这些功能，我们可以潜在地衡量影响我们正在研究的应用程序的异常类型（即内存泄漏和未终止线程）对系统的影响。 但是，根据要解决的异常类型，用户可以更改要使用的系统功能。 此阶段的输出包括一组行数据，这些行数据表示系统功能沿许多系统运行的演变。
 
   
   ### B.数据点聚合和附加指标
   
   在此阶段的第一步中，将根据用户定义的时间间隔生成聚合数据点。 聚合是根据图2所示的方案完成的。
   每个输入数据点（图中黑色显示）基于Tgen的值放置在时间轴上。 因此，落入同一时间间隔的所有数据点都将用于生成一个聚合数据点，这意味着系统特征的所有值均在聚合数据点中平均。 后续步骤包括向每个聚合数据点添加一些指标。 具体来说，对于每个系统特征j，根据以下公式计算斜率：
   
   公式
   
   其中xstart j和xend j是该时间间隔内第一个和最后一个原始数据点的特征j的值
   聚合数据点的数量。 斜率的值将添加到汇总数据点。 引入这些斜率会增加有关系统动力学的更多知识，这可能会显示出高度可变的行为。 例如，某些系统可能会显示资源使用率随时间不断增加，直到崩溃点真正逼近为止。 那时，某些参数可能会快速增长，甚至呈指数增长。 在这种情况下，可以将斜率解释为导数函数的简单近似，可以证明这种斜率可以有效地迅速检测即将发生的碰撞点。 作为一个具体情况，让我们考虑上面指定的SWused功能。 如果系统由于内存耗尽而崩溃，则在接近崩溃点时，SWused将开始更快地增长。 因此，可以有效地利用斜率来建立预测模型。
   沿后续固定大小的时间间隔聚合数据点的一种动机是，获得了沿时间的系统行为的更精确的图像。 实际上，取决于例如当前的工作负载，原始数据点的生成可能由于例如操作系统的调度器而在某种程度上引起偏差。 特别是，一旦系统接近崩溃点，该偏斜可能会产生更大的影响，因此无法随时间提供系统行为的常规表示。 另一个动机与以下事实有关：大量数据点可能需要大量时间才能生成预测模型。 考虑到要建立一个准确的模型需要很多次运行，并且考虑到一次运行中的大量数据点，这次的时间可能非常长。 数据点聚合可减少数据点的数量，而不会影响模型的准确性。
   在存储在数据点中的功能中，我们包括Tgen，即表示自系统启动以来经过的时间的时间戳。
   F2 PM从Tgen导出一个附加的导出度量，即两个连续数据点之间的生成时间。 此派生的度量允许捕获受监视系统中发生的过载。 实际上，在系统过载的情况下，由于系统负载的增加，这一代间时间预计会增加。
   为了证明这一点，我们使用WEKA [13]（使用快速线性回归[14]）在代间时间和客户响应时间之间进行了相关过程，并使用了application1来评估建议的F2 PM。  （稍后将在第四节中讨论）。
   相关过程为预测的对象建立模型
   
   图2.数据点聚合
   
   
   
   1 RT（地面真相）是从客户那里测量的，这些客户仅使用软件探针进行了此项研究。 实际上，F2 PM不需要对应用程序使用中涉及的软件进行任何修改。
   
   
   
   图3.响应时间相关
   
   
   
   
   RT，即仅从代间时间的测量开始，对从远程客户端获得的实际RT的估计。 在图3中，我们报告了此关联过程的结果。 显示了三条曲线：测得的RT（称为响应时间），测得的数据点的代间时间（称为“生成时间”）以及相关模型的结果（根据数据点的代间时间进行评估）（称为 作为相关RT）。 从图中可以看出，当系统遇到内存泄漏和未终止线程时，数据点的生成时间和RT（实际情况）都在增加。 因此，代间时间是捕获受监视系统过载的影响的重要措施。 用户可以为此附加功能指定特定的阈值，以便根据F2 PM认为系统发生故障的条件进行微调。 这种关联具有很大的影响，并且可以应用于差异化的上下文。 实际上，该技术可以有效地用于，例如，对最终用户看到的响应时间进行实用的估计，而无需在端点上对软件进行任何修改。
   最后，在聚合过程结束时，对于每个聚合数据点，都会计算RTTF。 这是通过利用失败事件来完成的，失败事件已在初始监视阶段添加到数据历史记录中。
   
   ### C.功能选择
   
   在此阶段，解决系统特征和添加指标的最佳子集的问题。 对于大型/复杂系统，甚至数千个功能都可以
   参与（例如，在某些与云相关的环境中[15]），此选择可以显着降低模型生成阶段的复杂性，并具有更简单（可能更有效）的系统行为表示。 实际上，此阶段旨在确定那些在RTTF预测中具有（逐渐）更大影响（权重）的特征。 如图1所示，该阶段的执行是可选的，因此用户可以选择在下一阶段F2 PM是应考虑整个参数集，还是仅考虑在此阶段选择的参数。 正如稍后将在第IV节中讨论的那样，此选择可能会影响模型生成的及时性及其准确性。
   特征选择基于套索正则化[16]。
   通过对我们的情况应用套索正则化方法，对于给定因子λ的给定向量λ，我们获得了一个向量β作为输出，其元素是向量xj的权重，从而最小化了以下目标函数：
   
   
   公式
   
   
   其中n是来自聚合步骤的数据点的数量，xj是每个数据点的输入要素（自变量）值的向量，yj是特定数据点的因变量（RTTF）的关联值，并且 V（yj，β，xj）等于（yj-βTxj）2。
   对于λ∈λ的每个值，计算出的向量β包括非零元素的（子）集合。 与向量β的零元素相关联的所有特征和添加的量度均从训练集中滤除。 通常，在增加λ的值的同时，向量β的更多元素可能等于零。
   特别地，这些元素可能是在RTTF评估中权重较小的元素。 因此，使用较高的λ值的效果是减少了要在ML模型中使用的所选特征的数量。 此阶段的输出是许多训练集，每个训练集都包括所选功能和添加的度量的子集。
   
###    D.模型生成和验证
此阶段旨在生成和验证一组预测模型，这些模型是通过使用先前阶段中生成的训练集构建的。 我们在F2 PM中包括了六种用于建立预测模型的ML方法，即线性回归[14]，M5P [17]，REP-Tree [18]，作为预测器的拉索[16]，SupportVector Machine（SVM）[19]和 最小二乘支持向量机[20]。 这套方法包括线性方法和非线性方法。 但是，用户可以通过添加其他方法或删除其中一些方法来定制集合。 在下文中，我们提供了上述方法的描述。
   线性回归[14]是一种对（标量）因变量与一个或多个解释变量之间的关系进行建模的方法。 给定一个定义为n个统计单位的{yi，xi1，...，sip} n i = 1的数据集，线性回归模型假定因变量yi与回归变量xi的p向量之间的关系是线性的。 这种关系是通过扰动项或误差变量εi建模的，后者是一个不可观察的随机变量，会增加噪声
   
   与因变量和回归变量之间的线性关系。 因此，模型采用以下形式：yi =β1xi1+··+βpxip+εi= xT iβ+εi，i = 1，...，n（3）M5P [17]是具有线性回归可能性的决策树 节点上的功能。 首先，使用决策树归纳算法构建一棵树，但不是使每个内部节点的信息增益最大化，而是使用拆分准则，该准则将每个分支下的类值的子集内变化最小化。 如果到达节点的所有实例的类值变化很小，或者仅剩余几个实例，则M5P中的拆分过程将停止。 第二，从每片叶子上修剪掉树。 修剪时，内部节点将变成具有回归平面的叶子。 第三，为避免子树之间出现明显的不连续性，应用了一种平滑过程，该过程将叶子模型预测与沿着返回根的路径上的每个节点结合在一起，并通过将其与线性模型预测的值结合起来在每个节点上对其进行平滑 该节点。
   REP-Tree [18]是一种快速决策树学习器。 它使用信息增益/方差构建决策/回归树，并使用减少错误的修剪（带有后向拟合）修剪它。 仅对数字属性的值排序一次。  C4.5的使用小数实例的方法[21]处理缺失值。
   作为参数[16]的套索（Lasso）根据参数λ生成向量β，其元素是向量xj的权重，这使等式（2）所示的目标函数最小。 拉索作为预测变量的应用基于用于拉索正则化的相同数学，但是目标是不同的。 实际上，尽管在正则化过程中我们有兴趣确定β向量，但是在预测过程中，我们利用已经计算出的β向量来评估预测模型，该模型以闭式方程表示。
   支持向量机[19]在高维或无限维空间中构造一个超平面或一组超平面，可用于分类，回归或其他任务。
   直观地，通过超平面可以实现良好的分离，该超平面到任何类别的最近训练数据点都具有最大距离（所谓的功能裕量），因为通常裕量越大，分类器的泛化误差越低。
   最小二乘支持向量机[20]给定训练集{xi，yi} N i = 1，其中输入数据xi∈Rn和相应的二进制分类标签yi∈{-1，+1}，SVM分类器，根据 Vapnik的原始公式[19]满足以下条件：如果yi = +1，则wTφ（xi）+ b> 1，如果yi = -1，则wTφ（xi）+ b <-1。
   （4）等于yi wTφ（xi）+ b≥1，i = 1，...，N，其中φ（x）是从原始空间到高处（可能是无穷大）的非线性映射 ）尺寸空间。
   通过使用应用于不同训练集的不同ML方法生成模型集后，便会开始验证阶段。 此阶段包括通过使用包含在样本中的样本的子集（验证集）（可能不用于模型训练）来计算多个指标。
   
   训练集。 因此，为每个模型提供以下度量：平均绝对预测误差（MAE）：它是预测RTTF与实际RTTF之间差异的平均值。 计算公式为：MAE = 1 n n i = 1 | fi-yi |  ，（5）其中，fi是预测值，yi是观测值，n是验证集中的样本数。
   相对绝对预测误差（RAE）：相对于简单的预测因子，即实际测量的平均值。
   RAE通过将总绝对误差除以简单预测变量的总绝对误差来归一化。
   RAE = n i = 1 | fi − yi |  n i = 1 | Y − yi |  ，（6）其中Y = 1 n n i = 1 | yi |  。  （7）最大绝对预测误差（MAE）：它是最大预测误差，即| fi-yi |集合中的最大值。 对于验证集中的每个样本。
   软均值绝对预测误差（S-MAE）：除当| fi-yi |值外，它均按MAE计算。 小于给定阈值，则被认为等于零。
   训练时间：这是学习方法用于构建模型所需的时间。
   验证时间：这是完成模型验证所需的时间，包括上述误差的计算。
   以上度量为用户提供了有用的信息，用于比较F2 PM产生的不同模型。
   
   ### E. F2 PM的其他实用程序
   为了进一步增强F2 PM的适用性，我们提供了其他实用程序，可以在主要框架中使用。
   这些实用程序中的两个可用于以综合方式将异常注入系统中。 这可用于，例如，在合成环境中测试F2 PM或加快数据点的收集以用于以后的培训。 这些实用程序的目标是根据不相关的分发功能来生成人为的内存泄漏并分离未终止的线程。 在这种情况下，硬件系统可能在不同的异常负载下承受压力，这使得F2 PM可以探索许多可能的系统配置，从而导致崩溃。
   内存泄漏是通过定期分配可变大小的连续内存块并将虚拟数据写入其中而产生的。 写入数据对于模仿错误的实现至关重要，否则，底层操作系统内核可能并不会真正为缓冲区分配物理内存（取决于其内部实现），仅
   虚拟内存将被分配，从而不会占用实际的物理空间。
   泄漏生成器的每次激活都利用两种统计分布：一方面，我们依靠统一分布来定义每次泄漏的大小（在用户启动时指定的间隔内）。 这样，我们可以模仿一种通用行为，在这种行为中，应用程序既需要小型缓冲区，也需要大型缓冲区，以进行其工作，而错误的实现可能不会释放这两种缓冲区。
   第二个统计分布是指数分布，用于绘制下一次内存泄漏发生之前的等待时间。 随机均匀地（再次以用户在启动时指定的间隔）均匀地绘制此指数分布的平均值。 这使我们可以或多或少地模仿软件“故障部分”的执行。
   与内存泄漏的情况类似，我们采用了一种指数分布方式来绘制连续两个连续的未终止线程之间的时间跨度。
   指数分布的平均值在启动时随机地均匀绘制，同样在用户定义的范围内。
   同样，我们强调仅依靠这些工具可能无法允许F2 PM建立预测模型，该模型在任何对实际（非合成）应用程序的利用下都是正确的，但是它们可以用作实际数据的补充 在受控环境中，在真实系统应用程序上收集数据。
   此外，F2 PM附带有一个瘦客户端，称为功能监视客户端（FMC），可以将其安装在受监视的系统上。 该客户端的目标是定期收集系统功能度量并生成数据点。 可以使用此自定义瘦客户端代替其他第三方工具，例如collected [22]。 当受监视的应用程序托管在与执行培训过程不同的计算机上。 在我们的实现中，FMC在一个数据点的生成和下一个数据点的生成之间等待大约2 1.5秒。 这也使我们能够捕获非常高的系统功能可变性，并避免仅出于监视目的而盗用过多的计算能力。
   FMC使用标准TPC / IP套接字连接到最后一个实用程序，即功能监视器服务器（FMS）。
   该技术解决方案允许将FMC / FMS部署在受监控的同一台计算机上，也可以部署在不同的计算机上。
   如果其他系统监视工具无法直接使用，则这种灵活性使用户可以监视本地和远程应用程序的行为。
   
##   IV。 实验数据

## 五，结论

   在本文中，我们提出了创新的F2 PM框架，用于生成应用程序的RTTF预测模型。
  我们方法的优点之一是F2 PM可以直接使用，而无需在应用程序中进行手动修改/干预。 另外，它可以由用户根据特定的类别进行定制 
  
   应用和/或异常类型。
   F2 PM使用不同的机器学习方法来生成模型，从而允许用户根据一组度量标准来确定最适合其需求的模型。
   我们演示了如何基于流行的电子商务基准在Web应用程序中使用F2 PM。
   我们提出了一组评估F2 PM的实验结果。
   在我们的特定测试平台场景中，我们发现F2 PM使我们能够以较短的培训时间和较高的准确性为应用程序故障选择预测模型。