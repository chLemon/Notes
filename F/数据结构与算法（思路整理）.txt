清华邓俊辉
# 1. 绪论
## a. 计算
## b. 计算模型
+ 问题的规模往往是决定成本的主要因素（不绝对）
主要讨论时间成本
$T(n)$ = 用特定算法A求解某一规模为n的实例，所需要的计算成本
但是有时候**运气因素会影响计算成本**，稳妥起见，**考虑最坏情况（成本最高）**

+ 对特定问题的不同算法的评价：
为了给出客观评判，抽象出一个理想的平台或模型：图灵机（Turing Machine）、RAM（Random Access Machine）
可以将**算法运行时间**转化为**算法需要执行的基本操作次数**
## c. 大O记号
+ 规模足够大之后，注重考察成本的增长趋势
+ 渐进分析：在问题足够大之后，计算成本如何增长
+ 大O记号（big-*O* notation）
   $T(n)=O( f(n) )$,  iff【if and only if】、 ∃c > 0，当n >> 2【>>：远大于】后，有$T(n) < c * f(n)$``
+ 与T(n)相比，f(n)更简洁，但依然反映前者的增长趋势，是T(n)的一个**上界**
  + 常系数可忽略
  + 低次项可忽略
+ bigΩ：$T(n)=Ω( f(n) )$：$∃c > 0$，当n >> 2后，有$T(n) > c * f(n)$，是T(n)的一个下界
+ bigΘ：$T(n)=Θ( f(n) )$：$∃c_1>c_2 > 0$，当n >> 2后，有$c_1 * f(n)>T(n) > c_2 * f(n)$

**一般考虑悲观情况，大O，特定情况下才考虑Ω和Θ**
+ O(1)
常数复杂度，这类算法的效率最高
+ O(logn)
对数复杂度，或对数多项式复杂度。
  + 常底数无所谓。不用注明底数
  + 常数次幂无所谓
  + 对数多项式（ploy-log function），对数的多项式，可以参照普通多项式，忽略低次项
  + 这类算法非常有效，复杂度无限接近于常数
+ O($n^c$)
多项式复杂度
  + 线性：O(n)
  + 这类算法的效率通常认为已可令人满意
+ O($2^n$)
指数复杂度
  + 这类算法的计算成本增长极快，通常被认为不可忍受
  + 从O($n^c$)到O($2^n$)，是从**有效算法**到**无效算法**的分水岭
## d. 算法分析
复杂度分析主要方法：

迭代：级数求和

递归：递归跟踪+递推方程

### 级数

+ 算术级数：与末项平方同阶
$$
T(n) = 1 + 2 + ... + n = \frac{n(n+1)}{2} = O (n^2)
$$

+ 幂方级数：比最高幂次高出一阶
$$
T_2(n) = 1^2 + 2^2 + ... + n^2 = \frac{n(n+1)(2n+1)}{6} = O (n^3)
$$

+ 几何级数( a > 1 )：与末项同阶
$$
T_a(n) = a^0 + a^1 + ... + a^n = \frac{a^{n+1}-1}{a-1} = O (a^n)
$$

+ 收敛级数
$$
1 + \frac{1}{2^2} + ... + \frac{1}{n^2} < 1 + \frac{1}{2^2} + ... = \frac{π^2}{6} = O(1)
$$

+ 可能未必收敛，然而长度有限
  + 调和级数
$$
h(n) = 1 + \frac{1}{2} + \frac{1}{3} + ... + \frac{1}{n} = Θ(logn)
$$

  + 对数级数
$$
  log1 + log2 +log3 + ... + logn = log(n!) = Θ(nlogn)
$$

### 循环和级数
+ 例1
``` 
    for (int i = 0; i < n; i++)
    for (int j = 0; j < n; j++)
        O1Operation(i,j); //O(1)操作
```
算数级数：
$$
n + n + ... + n = n * n = O(n^2)
$$
相当于一个正方形的面积
+ 例2
```
    for (int i = 0; i < n; i++)
    for (int j = 0; j < i; j++)
        O1Operation(i,j);
```
算数级数：
$$
0 + 1 + ... + (n-1) = \frac{n(n-1)}{2} = O(n^2)
$$
相当于一个三角形的面积
+ 例3
```
    for (int i = 0; i < n; i++)
    for (int j = 0; j < i; j+= 2013)
        O1Operation(i,j); 
```
算数级数：
相当于j的坐标轴做了一个压缩：j/2013，依旧是一个三角形，$O(n^2)$

+ 例4
```
    for (int i = 0; i < n; i <<= 1) //i左移一位，相当于i = 2i
    for (int j = 0; j < i; j+= 2013)
        O1Operation(i,j);
```
几何级数：
$$
1 + 2 + 4 + ... + 2^{|log_2(n-1)|} = 2 ^{|log_2n|} - 1 = O(n)
$$
相当于一个螺旋增加正方形的面积，最后的面积是2n
【https://www.bilibili.com/video/av49361421?p=12 的最后】

### 取非极端元素例子
无论输入规模n多大，算法需要的执行时间都不变
### 起泡排序分析
+ 不变性：经k轮扫描交换后，最大的k个元素必然就位
+ 单调性：经k轮扫描交换后，问题规模缩减至n-k
+ 正确性：经至多n趟扫描后，算法必然终止，且能给出正确答案【由不变性和单调性推导得出】
### 封底估算
1天 = 10^5 sec
1生 = 1世纪 = 3 × 10^9 sec
**三生三世 = 10^10 sec**【三生三世的一天，就相当于一天中的一秒】
宇宙大爆炸至今 = 10^21 sec
普通PC 1GHz 10^9 flops

## e. 迭代与递归
问题：数组求和，迭代
实现：
```
    int SumI(int A[], int n){
    int sum = 0; //O(1)
    for (int i = 0; i < n; i++)  //O(n)
        sum += A[i]; //O(1)
    return sum; //O(1)
    }
```
时间复杂度：T(n) = n + 2 = O(n)
空间：一般不考虑输入本身所需要占用的空间，本题为O(2)

### 减而治之【Decrease-and-conquer】

分解：其一平凡，另一规模缩减

### 递归跟踪（recursion trace）分析

检查每个递归实例，求和

### 递推方程
+ 递归基
### 分而治之【Divide-and-conquer】

划分子问题，规模大体相当

## f. 动态规划
+ DSA（Data Structure and Algorithm）
+ 所谓的动态规划，可以理解成用递归给出一个初步的解之后，再通过迭代提高效率。

### fib()：递归
`int fib(n) { return (2 > n) ? n : fib(n-1) + fib(n-2); }`
n稍大就特别大
分析：
$$
T(n)=2*S(n)-1=O(fib(n+1)）=O（Φ^n）=O(2^n)
$$

原因分析：

大量fib需要被重复计算

#### fib()：迭代

解决方法A：记忆memoization，将已计算过实例的结果制表备查
解决方法B：动态规划dynamic programming
颠倒计算方向：由自顶而下递归，改为自底向上迭代

```
    f = 0; g = 1;
    while(0 < n--){
        g = g + f;
        f = g - f;
    }
    return g;
```
g和f永远代表了相邻的两个斐波那契数
T(n)=O(n)，而且仅需要O(1)空间！

### LCS(Longest Common Subsequence最长公共子序列):递归

子序列：按原来的相对次序构成的若干字符。

计算长度。

思路：从末尾字符开始

1. 若A[n] = 'X' = B[m]，两者相同，该元素是子序列的一部分
2. 若不同，则分为2种情况，一种是是A的元素可能会是子序列，一种是B，分开计算并取更大者

```
0) 若n = -1或m = -1，则取作空序列("") //递归基
1) 若A[n] = 'X' = B[m],则取作LCS(A[0,n),B[0,m)) + 'X'  //减而治之
2) 若A[n] ≠ B[m]，则在LCS(A[0,n],B[0,m))与
                    LCS(A[0,n),B[0,m])中取更长者  //分而治之
```
单调性：无论如何，每经过一次比对，原文提的规模必可减小
具体的，作为输入的两个序列，至少其一的长度缩短一个单位

最好情况下（只出现第一种情况）下，只需O(n+m)时间
但问题在于，在第2种情况下，原问题将分解为2个子问题，而它们在随后进一步导出的子问题可能雷同【有点像fib问题，同一个子问题会被重复计算很多次】

最坏情况下，LCS(A[0, a], B[0, B])出现的次数为
$$
C_{n-a}^{n+m-a-b} = C_{m-b}^{n+m-a-b}
$$
>子问题LCS(A[0, a], B[0, B])出现的次数可以看作是从原问题出发（右下角(n,m)），有多少条路径会走到(a,b)这个点
>n+m-a-b的含义是n-a+m-b，是路径的总长度
>n-a和m-b分别是水平的长度和竖直的长度

特别的，LCS(A[0],B[0])的次数可多达
$$
C_{n}^{n+m} = C_{m}^{n+m}
$$
当n=m时，为O(2^n)
#### LCS：迭代
0) 将所以子问题列成一张表
1) 颠倒计算方向，从LCS(A[0],B[0])出发依次计算出所有项

|      |      |  a   |  b   |  c   |  d   |  e   |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|      |      |  0   |  0   |  0   |  0   |  0   |
|  a   |  0   |  1   |  1   |  1   |  1   |  1   |
|  p   |  0   |  1   |  1   |  1   |  1   |  1   |
|  p   |  0   |  1   |  1   |  1   |  1   |  1   |
|  l   |  0   |  1   |  1   |  1   |  1   |  1   |
|  e   |  0   |  1   |  1   |  1   |  1   |  2   |

# 2. 向量
## a. 接口与实现
Abstract Data Type抽象数据类型 = **数据模型** + 定义在该模型上的**一组操作**：*说明书*
Data Structure数据结构 = 基于某种**特定语言**，实现ADT的**一整套算法**

### 向量ADT
构造

\_size：当前的实际规模，\_capacity：总容量，初始设定成2倍的size，\_elem：内部数组名

## b. 可扩充向量

创建新数组，扩容后复制，释放原数组

+ 递增式扩容：
初始为0的空向量，插入 n = m*I >> 2个元素
每次扩容时间成本O(n)
+ 加倍式扩容：
初始为0的空向量，插入 n = 2^m >> 2个元素
每次扩容时间成本O(1)



**平均分析 与 分摊分析**

平均复杂度或期望复杂度：概率求期望，会割裂操作相关性和连贯性

分摊复杂度：连续实施足够多操作，总成本分摊


## c. 无序向量
T为可**判等**的基本类型，或已重载操作符“==”或“!=”

### 插入
注意复制从后往前
### 区间删除
复制从前往后
### 查找
从hi开始逆向查找，输入敏感：最好O(1)，最差O(n)
### 单元素删除
视作区间删除的特例[r]=[r,r+1)
### 唯一化
从前往后开始考察。前缀中寻找雷同者，无雷同继续考察后继，有雷同则删除
O($$n^2$$)

### 遍历
## d. 有序向量
T为可**比较**的基本类型，或已重载操作符“>”或“<”
### 甄别：
相邻逆序对的数量，0为有序
### 唯一化
首元素开始，从前往后逐一比对，雷同删除后者，否则向后
O(n^2)

首元素开始，往后比对，有2个标签，i与j。i与j刚开始都指向0，然后j开始向后移动；跳过雷同者，发现不同时，不同的元素向前移至紧邻于i的右侧（复制），i右移一位，j继续移动，最后统一删除尾部
O(n)

## 二分查找
### 接口
search(e,lo,hi)
#### 语义
为了便于自身的维护（插入方便），约定：

1. 失败给出新元素适当的插入位置；

2. 若允许重复，每次都给出最后的秩（考虑插入，为了与插入次序一致）

### 原理（不完全符合语义）
算法A：
  x=S[mi]
当lo<hi

1. e<x，左侧深入
2. x<e，右侧深入
3. e=x，返回x

复杂度：O(logn)

#### 查找长度
**更精细地评估查找算法的性能**：

考察关键码的比较次数：if语句
分别针对成功、失败，从最好、最坏、平均等角度评估
算法A成功、失败时的平均查找长度大致为**O(1.5logn)**

### fib查找

【平衡的用意：回避最坏情况，让失败都出现在最深处的底层】往左右分支时比较次数不同（向左1次，向右2次）

那么就让左边更大，右边更小，更平衡

取mi = fib(k-1) - 1，左边长fib(k-1) - 1，右边长fib(k-2) - 1

#### 复杂度
以A[$$λ_n$$]为轴点分割，二分查找为λ=0.5，Fibonacci查找对应于λ=φ=0.6180339...
设平均查找长度为α(λ)*$$log_2(n)$$，根据递推式求极限，λ=φ时，α(λ)=1.4404...最小

### 二分查找改进

直接将左右分支转向的代价都变成1次比较

#### 版本B：
把中点元素算入右区间，不过这样需要到最后才能确定成功与失败

1< hi-lo
e<x：深入左侧[lo,mi)
x<=e：深入右侧[mi,hi)

相比于A，最好时更坏，最坏时更好，性能更趋稳定

### **版本C：**
**考虑到语义，多个命中元素，返回最靠后者；失败是，返回小于e的最大者（含哨兵[lo-1]）**

```c++
Search(...){
    while(lo < hi){
        Rank mi = (lo + hi) >> 1;
        (e < A[mi]) ? hi = mi; lo = mi + 1;
        }
    return --lo;
}
```

如果e小于中点x，深入左侧，否则，直接深入右侧。如果刚好相当，最后返回的lo-1也正好是mi的值。

## e. 起泡（冒泡）排序
bubbleSort

逐趟扫描交换，每次都把当前最大的放在后面

O($$n^2$$)

### 改进：

有可能在中间的时候就已经全部有序了。

1. 设置整体有序标志 sorted，初值为true；若发生交换，置为false。
2. 若有一次未发生交换，则直接停止
（乱序限于[0,$$\sqrt{n}$$)时，仍然需要O($$n^{1.5}$$)）
### 再改进：

后面一段可能已经有序，但是还会重复排序

1. 设置一个秩last = lo，若逆序，交换时更新last，最后记录最右侧逆序对的位置
2. 下次bubble就只需要在[lo,last]之间进行即可
### 综合评价
起泡排序的三个版本在最好O(n)和最坏O($$n^2$$)时的性能是一样的，差异只在一般情况下而言。

起泡排序算法都具有**稳定性**：重复元素在输入、输出序列中的相对次序是不变的

## f. 归并排序
基于比较式的算法C.B.A(comparision based algorithm)求解排序算法都存在下界Ω(nlogn)
### 原理
分治策略：序列一分为二，子序列递归排序，合并有序子序列
O(nlogn)

### 主算法
1. 递归基：hi-lo<2，单元素区间，自然有序

2. 中点分界，递归两个序列

3. 归并merge()

### 二路归并
关注两个序列的首元素，每次取出首元素中更小的那个元素，后续元素进行顶替
### 实现
归并排序用的其实是一个特例，两个有序向量都来自于一个更大的序列

三个界桩：lo,mi,hi
A[lo,hi) = B[lo,mi) + C[mi,hi)

B新申请一段空间，A不需要，C也不需要

```
for (i,j,k=0;(j<lb)||(k<lc)){//退出条件：B、C元素都越界才退出

    if( (j<lb)&&(lc<=k ||(B[j]<=C[k])) ) A[i++]=B[j++]; //取出BC中更小的放入A。
    B更小的判断：j首先还在B里；然后如果k不在C了，短路算法直接true，如果k还在，判断大小
    
    if( (k<lc)&&(lb<=j ||(C[k]<B[j])) ) A[i++]=C[k++];  //取出BC中更小的放入A
}
```
### 复杂度
j+k=n【每次迭代j+k至少+1（每次循环中可能j会先变，然后会执行2条if）】
最坏情况下merge()复杂度为O(n)

故整体归并排序复杂度可计算：O(nlogn)

# 3. 列表
### 从静态到动态
+ 根据是否修改数据结构，所有的**操作**大致分为两类：
1. 静态：仅读取，数据结构的内容及组成一般不变：get、search
2. 动态：需写入，数据结构的局部或整体将改变：insert、remove
+ 与操作方式相对应，数据元素的**存储与组织方式**也分为两种：
1. 静态：
   数据空间整体创建或销毁
   数据元素的物理存储次序与逻辑次序严格一致
   可支持高效的静态操作
   例如向量
2. 动态：
   为各数据元素动态地分配和回收的物理空间
   逻辑上相邻的元素记录彼此的物理地址，在逻辑上形成一个整体
   可支持高效的动态操作
### 列表list
动态存储的典型结构
+ 基本组成单位：节点 node
+ 相邻接点互称彼此为 前驱（predecessor） 或 后继（successor）
+ 没有前驱/后继的唯一节点称作 首（first/front）/末（last/rear） 节点
### 访问方式
+ 向量：循秩访问call by rank
+ 列表：循位置访问call by position，由节点之间的互相引用找到特定的节点
## 无序列表
### 循秩访问
想重载下标操作符。

平均性能：O(n)

### 查找
顺序查找：O(n)
### 插入
O(1)
### 删除
O(1)
### 复制构造
复制每一个，然后insertAsLast
### 析构
反复删除第一个元素
### 唯一化
从前往后，不断考察前驱有没有相同元素。有的话删除前驱中相同的那个【之所以不删除当前元素，是因为接下来一步后移要找当前元素的后继，删除之前的更安全】

## 有序列表
### 唯一化
两个指针，p指向首节点，q为其后继，如果相同，就删除q；如果不同，p后移至q，q为p的后继
只需要遍历整个列表一趟，O(n)

### 查找
从后向前，相同返回，不同继续向前
最好O(1)，最坏O(n)，等概率时平均O(n)
排序并没有带来什么提升

### 其他
向量像RAM，列表像图灵机，call by rank和call by position

## 选择排序
从一堆里选出最大的，然后选出次大的... 选择排序
起泡排序也是一个选择排序

但是起泡排序的效率很差，最坏要O($$n^2$$)
每次选最大的时候都是一步一步的移动

### 思路
从后往前，每次选择出最大的，放到后面

### 放到后面的几个问题
1. 删除再插入，会导致new和delete，这两个操作非常耗时
2. 直接修改引用
3. 直接互换内容
4. 在找出来的最大值恰好OK的时候，不需要交换，但是并不需要为此加入if判断，这种情况概率很小，会得不偿失

### 选择最大的算法
从头到尾，挨着比对，记下最大的
（画家算法）
为了保证稳定性，取最大的时候，用<=，就算相等也会交换

### 性能
θ($$n^2$$)

看似与起泡算法差不多，但是这个算法的复杂度主要来自于比较操作，起泡算法来自于移动操作。成本相对较低。而且根据堆，可以改进比较操作。

## 插入排序
抓扑克牌
1. 判断位置
2. 插入当该插的地方

### 构思
从前往后，查找插入

in-place算法，就地算法，只需要O(1)的辅助空间
### 复杂度
最好：O(n)
最坏：O($$n^2$$)，查找是个算数级数，从后往前

平均性能：O($$n^2$$)

本质解释：相当于```O(I+n)```，I是逆序对的数量，对应查找，n是插入操作的总和

所以该算法的复杂度取决于规模，还取决于输入的特性（逆序对的数量，逆序程度），称之为**输入敏感算法**

# 4. 栈与队列
## 栈
LIFO：Last In First Out，后进先出
push，pop
可以用列表或向量派生。向量，注意方向。

## 栈应用：进制转换
### 算法思路
不断除以进制位数，直到商为0，然后把余数倒着写

### 实现
取余，余数入栈。n更新为商，直到商为0.然后把内容pop出来

## 栈应用：括号匹配
左右括号是否匹配

### 思路
消去一对**紧邻**的左右括号，不影响全局的匹配判断

顺序扫描表达式，遇到左括号入栈，右括号出栈。只有最后栈为空则匹配。（若遇到右括号栈已空或最后栈有括号，都失配）

### 为什么一定要用栈？
用计数器也可以做，如果只有一种括号。用栈是为了便于拓展至多种括号的情况。

## 栈应用：栈混洗
### 定义
考查栈	$$A = < a_1, a_2, ..., a_n]$$、$$B = S = ∅$$

<表示栈顶

只允许	将A的顶元素弹出并压入S，或	将S的顶元素弹出并压入B

若经过一系列以上操作后，A中的元素全部转入B中，则称B为A的一个栈混洗

即，A中的元素通过空栈S，进入到空栈B中

### 问题：计数
栈混洗的总数$$SP(n)$$

#### 解决思路
假设，A的第一个元素1可能在B中的位置是k。那么B中在1前有k-1个元素。A里还有n-k个元素。这两部分的栈混洗应该是独立的。

那么
$$
SP(N) = \sum_{k=1}^n SP(k-1)*SP(n-k)
$$

这个递推式就是catalan数
$$
catalan(n) = \frac{(2n)!}{(n+1)!n!}
$$

### 问题：甄别
任意三个元素能否按某相对次序出现在栈混洗中，与其他元素无关

$$<1,2,3]$$的栈混洗必然没有$$[3,1,2>$$。称为**禁形**。

禁形与栈混洗是充要条件

#### 算法
可以直接得出一个，通过遍历，O($$n^3$$)的甄别算法，考察$$(i,j,k)$$

考虑$$i<j$$，考察$$(j+1,i,j)$$，复杂度O($$n^2$$)

直接借助栈模拟，复杂度O(n)
每次pop前，S已空；或需要弹出的元素在S中，却不是顶元素，直接判断栈混洗非法

## 栈混洗与括号匹配
两者存在一一对应的关系，n个括号的合法匹配种类和n个元素的栈混洗个数相同。

## 栈应用：中缀表达式
### 思路
与括号匹配问题相似，找到相邻的两个括号。先计算，最终消除掉所有的运算符。

借助栈，将扫描过还不能处理的部分和已经处理的结果存在栈里，还没扫描的继续扫描

### 实现
#### 主算法
两个栈：一个存运算数，一个存运算符

当遇到一个数，直接入栈，操作符根据与栈顶操作符比较后处理

预先初始化将一个\0推入栈中，相当于一个左括号，与最后的终止符\0匹对。

#### 优先级表
事先指定优先级表。优先级表有>，<，=，空。
只有左括号与右括号的关系是=
还有终止符\0与终止符之间是=

#### 不同优先级的处理方式
$$<$$的情况：将当前运算符push进栈，考察下一个。栈顶小于当前运算符，如栈顶是+，当前是×。
$$=$$的情况：pop一下，考察下一个。括号的情况。
$$>$$的情况：执行相应的运算。弹出栈顶运算符，取出一或两个运算数进行运算。直接break，当前运算符指针不变。

## 栈应用：逆波兰表达式RPN
### 描述
不使用括号，即可表示带优先级的运算关系。（也摒弃掉了约定俗成）

运算符谁先出现，谁先计算

中缀表达式如：
$$
0 ! + 123 + 4 * ( 5 * 6 ! + 7 ! / 8 ) / 9
$$
对应的RPN为：
$$
0 ! 123 + 4 5 6 ! * 7 ! 8 / + * 9 / +
$$

### 手工转换法
先给表达式所有优先级都加上括号，然后把运算符移到对应的括号的右边，抹去所有括号即可。

运算符的位置可能会变。但是操作数的顺序不会变。

### 转换算法
中缀表达式的求值算法即实现了RPN的转换

即：
当是一个数字的时候，append到RPN中；当是一个运算符的时候，只有当>的时候，才会append

## 队列
队尾插入enqueue，查询rear
队头删除dequeue，查询front

FIFO先进先出
LILO后进后出

可以基于向量和列表派生。列表

# 5. 树
向量、列表：线性结构

树：半线性结构
## a. 一些概念
特殊的图

顶点：vertex
边：edge

有根树

子树

孩子child，兄弟sibling，父亲parent，度（出度）degree

有序树：兄弟间有次序

$$
e = \sum_{r∈V}degree(r) = n-1 = Θ(n)，边数=度的和=节点数-1
$$
故n+e与n同阶，之后讨论复杂度时，以n为参照

通路：衡量通路的长度，用边的数量。

连通图：任意两个节点间都有路径（边不会太少）
无环图：不含环路（边不会太多）

树：无环连通图。极小连通图。极大无环图。

故：任一节点v与根之间存在唯一路径。路径长度称为**深度**。

path(v)上的节点，都是v的祖先，v是它们的后代

根节点深度为0。

叶子：没有后代的节点

高度：所有叶子深度中最大者。

空树高度取作-1

## 树的表示
### 父亲孩子表示法
创建一个表（序列），记录下每个节点的内容 + 父节点 + 孩子节点。

孩子节点长度分布不平均，规整性非常差

### 长子兄弟表示法
纵：firstChild
横：nextSibling

## 二叉树
### 概念
节点度数**不超过2**的树

左孩子、左子树
右孩子、右子树
隐含有序

深度为k的节点，最多有$$2^k$$个
在含n个节点、高度为h的二叉树中
$$
h < n < 2^{h+1}
$$

当n = h + 1时，退化为一条单链
当n = $$2^{h+1} - 1$$时，为**满二叉树**

真二叉树：不含出度为1的二叉树

### 用二叉树描述多叉树
**有根**且**有序**的树都可以用二叉树来表示

长子兄弟法

## 二叉树实现
### 节点类BinNode

|        |  data  |        |
| :----: | :----: | :----: |
| lChild | parent | rChild |
| height |  npl   | color  |

笼统称其为一个位置。npl是左式堆要用的，color是红黑树要用的。

### 接口实现
#### size()
树的规模，包括自身（节点个数）
先计入自身，s=1。然后递归的计算左子树和右子树，分别加入s中。
O(n)

### 二叉树模板类
```_size,_root```

#### 高度更新
只有一个节点的树的高度：0
空树高度：-1

思路1：左孩子高度 与 右孩子高度 的更大者 +1

思路2：不断更新v与其历代祖先的高度 $$O(n=depth(x))$$

#### 节点插入
插入节点，更新当前节点高度及其历代祖先高度

## 二叉树相关算法
半线性结构，想办法转换为线性结构

### 遍历
按照**某种次序**访问树中各节点，每个节点被访问**恰好一次**

一个局部的子树可以分为：树根，左子树，右子树
T = V ∪ L ∪ R

如果根节点先于左右子树：**先序**。V | L | R

如果根节点位于左右子树中间：**中序**。L | V | R

如果根节点在左右子树之后：**后序**。L | R | V

层次遍历（广度遍历）：自上而下，先左后右

### 先序遍历
#### 递归
递归基：节点非空
访问当前节点，递归访问左子树，递归访问右子树
$$T(n) = O(1) + T(a) + T(n-a-1) = O(n)$$

这个线性只是渐近意义上的。因为递归的实现机制，其实还可以做得更好。

#### 迭代1
有一个辅助栈S，用来存放节点
根节点先入栈

循环：先弹出并访问当前节点，如果有右孩子，入栈；如果有左孩子，入栈。
直到栈为空

右孩子先入后出，左孩子后入先出。

#### 迭代2
##### 思路
定义：对于任何一棵子树，起始于树根，不断沿着左侧分支下行的链，称为左侧链。

任何一个树都可以抽象成。一条左侧链，和左侧链沿途的每个节点的一个右子树。

那么访问顺序就是，先访问左侧链，然后从低到高遍历访问右子树。

##### 实现
###### 左侧链访问实现
访问当前节点，右孩子入栈。当前节点指向左孩子，直到为空。

###### 主算法
全局只用1个栈。

循环：左侧链访问。然后栈弹出值作为下一个子树的根。一直到栈空break。

### 中序遍历
#### 递归
处理递归基
递归左子树，根，递归右子树
O(n)，常系数很大

#### 迭代
##### 思路
与先序遍历同理，同样将二叉树抽象为一根左侧链与左侧链节点的右子树。

局部上：先访问左孩子，再访问左孩子的右子树，再访问根节点

从根出发，沿左分支下行，直到最深的节点，它就是全局首先被访问的

##### 左侧链下行
用一个栈，将左侧链的每个节点都入栈

##### 主算法
循环：
每抵达一个节点，都认为进入了以这个节点为根的子树。
先将左侧链入栈。
然后pop，访问。
然后将当前节点的指针指向其右子树

直到栈为空

##### 复杂度
O(n)
常系数更小

### 层次遍历
垂直方向次序：有根后的深度
水平方向次序：二叉树，左右节点，同辈节点的次序。

自高向低，自左向右

前三个都是有逆序的，子节点会先于父节点被访问，而层次遍历是顺序的
#### 实现
引入一个队列
根节点入队

循环：
取出队首节点访问。左孩子入队，右孩子入队。
直到队列为空。

### 二叉树的重构
任何一个二叉树，都可以导出其先序、中序、后序的遍历序列。
那么在知道遍历序列后，能否重新获得二叉树？

#### 先序/后序 + 中序
r为树根
先序序列：
**r**	——L——	——R——
中序序列
——L——	**r**	——R——

可以对r进行定位，从而可以区分左子树和右子树。

由于L与R可能是空树，只凭借先序和后序序列是不行的。必须要有中序。

#### （ 先序 +  后序 ）× 真
真二叉树可以用先序和后序序列重构。
真二叉树：度数必须是偶数（0和2）

先序：
**v**	**l**——L——	**r**——R——
后序：
——L——**l**	——R——**r**	**v**

可以区分出左右子树

# 6. 图

## 术语
数学意义而言的图：定点 + 边 $$G = (V; E)$$
vertex：n = |V|
edge|arc：e = |E|
被边相连的两个点，存在**邻接关系**（点与点）
点与邻接关系的关系，叫**关联关系**（点与边）

若邻接顶点u和v的次序无所谓，则$$(u,v)$$为**无向边**。
所有边均无方向的图，即**无向图**。

反之，**有向图**中**均**为**有向边**。
u，v分别称作边（u，v）的尾（tail）、头（head）

混合图


本课重点关注**有向图**。有向图可以表示和实现无向图和混合图。

路径

简单路径：不含重复节点
路径：一般性的
环：头尾相同。有简单环和一般环。
有向环图DAG
欧拉环：经过所有边一次，恰好一次
哈密尔顿环路：经过所有点，且恰好经过一次

## 实现
邻接矩阵与关联矩阵

### 邻接矩阵
点与点的n×n矩阵

### 关联矩阵
点与边的n×e矩阵

### Vertex

状态status：UNDISCOVERED（初始值），DISCOVERED，VISITED
inDegree、outDegree、data
遍历相关：
dTime，fTime
parent、priority（优先级）

### Edge
data、weight
状态status：UNDETERMINED，TREE，CROSS，FORWARD，BACKWARD

### 图的实现
顶点集：一个向量
边集：一个二维向量，邻接矩阵。

### next neighbor
点与点的连边关系保存在邻接矩阵里。
点i的连边都在i行里。
从后往前依次遍历。

### first neighbor
```
return nextNbr(i,n); //n可以认为是一个和谁都相邻的哨兵，来启动算法
```

### 边的插入删除
指向对应的矩阵位置。更新边数、出度、入度即可。

### 顶点插入
1. 邻接矩阵增加一列
2. 邻接矩阵增加一行，边集合增加一个元素
3. 顶点集合增加一个元素

删除一样，先删除行，再删除列，最后删除顶点

### 分析
缺点：空间会浪费。有$$n^2$$的空间用于存边，但通常不可能这么多。

平面图：可以嵌入于平面的图（画在平面上边不相交）。根据欧拉公式，空间利用率1/n

## 相关算法
化繁为简，通过遍历，转换为树

## 广度优先搜索BFS
在图中的遍历，更多的体现为，针对某种目标的查找过程，所以称为搜索。

### 思路
自顶点开始广度优先搜索：
先访问顶点，然后访问它的所有邻居（**尚未访问**的邻接顶点），并保留顶点与之的边。依次访问它们所有**尚未访问**的邻接顶点，并保留通往它们的边。如此反复。

然后就形成了一棵**支撑树**。

而且也就是树的层次遍历。

### 代码实现
一个队列。
预处理：顶点入队。状态转换：UNDISCOVERED --> DISCOVERED
循环：
  顶点出队，访问（可能会有各种各样的操作）
  考察所有邻居，根据邻居的状态分别处理
    UNDISCOVERED，转换为DISCOVERED，入队；
      对应的边，UNDETERMINED-->TREE，是最后构成支撑树BFS Tree的边，顶点为邻居的父亲
    else：对应的边置为CROSS
  邻居全部访问完，状态转换为：VISITED
直到队列为空

### 考虑不连通的情况
主算法：
检查每一个顶点，如果是UNDISCOVERED，就对其进行一次BFS搜索

### 复杂度
理论$$O(n^2)$$
实际O(n+e)：n×n中的一个n，for循环遍历某一行找邻居引入的，1操作简单，2地址连续，在高速缓存中

### 最短路径
留下的支撑树的边刚好是最短通路

## 深度优先搜索DFS

### 算法
访问顶点s
若s有**尚未被访问**的邻居，则任取其一u，**递归**执行DFS(u)
否则，返回

即：先访问s，然后访问s的邻居u，如果u没有邻居，会回到s，再找s的邻居

### 框架
访问v，状态转为DISCOVERED
循环：
  枚举v的每一个邻居u：
    UNDISCOVERED：v，u的边置为TREE；v为u的父亲；递归DFS(u)
    DISCOVERED：v，u的边置为BACKWARD
    VISITED（switch里的default）：看v和u谁更早被发现，v更早标位FORWARD；u更早标记CROSS（通过每次访问v时记录dTime）
将v状态转为VISITED

边的状态的说明：
BACKWARD会是有向图里，从后代回连到祖先。一旦发现BACKWARD边，就会出现一个回路。
FORWARD：从祖先连到后代
CROSS：子代之间的连接

### 有向图的可达域问题
有向图有的节点可能会在一次DFS算法里访问不到。
参照BFS算法，外设循环。

## 嵌套引理（括号引理）
在图遍历算法里有2个时间标签，dTime和fTime，前者在v第一次访问的时候记录时间，后者在彻底访问结束后（遍历完所有邻居）记录。

定义 顶点的活动期=(dTime, fTime)
括号引理：
给定有向图及其任一DFS森林。
两个节点的祖先后代关系与活跃期的包含关系对应：

u是v的后代：祖先的活跃期包含后代的活跃期（子集关系）	
u是v的祖先：
u与v“无关”：活跃期互不相交（交集为空）

# 7 二叉搜索树BST
BBST：平衡二叉搜索树

## 规范
### 寻关键码访问
call-by-key
数据项之间依照**关键码**区分彼此

关键码：支持**大小比较**和**相等比对**

变量\_hot
### 有序性
顺序性：
任一节点均**不小于**/**不大于**其**左**/**右**后代
【左小右大】

从而BST的**中序遍历序列**，必然**单调非降**

## 算法
### 查找
从上往下查找，对应在中序遍历序列上就是二分查找。

#### 实现
##### 递归版
递归基：树为空
相等返回
不等，在判断一次大小后，递归调用左子树或右子树

O(h)

##### \_hot变量
初始置null，每次递归下一层前，记录当前（非空）节点

查找成功：返回目标关键码的父节点
查找失败：返回最后访问的真实存在的节点（目标空节点的父节点）

引入假想哨兵，返回值总是等效于命中节点，hot为命中节点的父亲

### 插入
先用search。返回值是应该插入的位置，hot是父亲。更新高度
复杂度：O(h)

### 删除
查找，删除节点，更新高度

#### 删除节点细节：
##### 情况1：有一个子树是空的
删除然后替换为其另一个子树

##### 情况2：两个子树都还在
找到直接后继：BinNode中有实现。先进入右子树，然后沿着左侧分支不断下行到底。

然后当前节点和直接后继进行对换。变成了情况1，删除

修改hot变量的指向，更新高度

#### 复杂度
O(h)

### 复杂度分析
都与高度有关
极端情况下，退化成列表，就成O(n)了

估算高度
#### 随机生成
关键码全排列，然后生成树，有n！个（从高到低长）
高度$$O(logn)$$

#### 随机组成
考察所有的拓扑情况，数量catalan(n)
高度$$O(\sqrt{n})$$

#### 比较
随机生成会有所重复，不同的关键码可能会生成相同的BST，过于乐观

#### 理想平衡
节点固定，子树高度越接近，全树高度越低

n个点的二叉树，高度不低于$$\lfloor log_2n\rfloor$$，那么高度恰为$$\lfloor log_2n\rfloor$$时候，称为理想平衡

#### 适度平衡
理想平衡出现概率极低，维护成本过高，适当放松标准

高度渐进不超过$$O(logn)$$

适度平衡的BST，平衡二叉搜索树BBST

### 中序遍历的歧义性
同一个中序遍历序列可能会对应不同拓扑结构的树

称它们为等价BST。
等价BST：
上下可变
左右不乱

### 等价BST变换
zig(v)：绕v顺时针旋转
zag(v)：绕v逆时针旋转

## AVL
定义**平衡因子**：$$balFac(v) = height( lc(v) ) - height( rc(v) )$$
左子树的高度减去右子树的高度
AVL树的条件：
$$\forall |balFac(v)| \le 1$$

### 插入、删除与失衡
插入与删除都可能会导致AVL的失衡。

插入算法的失衡可能会发生在其历代祖先上，但是只需要一次恢复即可。

删除的失衡可能会发生在父节点上，只有一个节点失衡，但是恢复可能会引入新的失衡。
### 插入
搜索，创建，插入

从父节点出发，依次检查各代祖先是否失衡。一旦发现失衡，祖孙三代开始恢复。恢复后祖先们的高度不变（子树高度不变）。
否则只需要更新高度既可以。

### 删除
搜索，删除

从父节点向上检查各代祖先。一旦失衡，恢复，并更新高度。全树的高度可能下降。

### 3+4重构
祖孙三代：g、p、v【最低的失衡节点，其较高子树的根，较高子树的较高子树的根】
按中序遍历命名：a、b、c
子树：$$T_0、T_1、T_2、T_3$$
命名过程：穷举4种情况，依次处理。

重新拼接为：
         b
      a      c
$$T_0、T_1、T_2、T_3$$

### 综合评价
查找、插入、删除均O(logn)
O(n)存储空间

缺点：
1. 要额外维护平衡因子
2. 实测性能与理论值有差距
3. 动态变化后，拓扑结构的变化量可能高达Ω(logn)【删除】

# 8. 高级搜索树
## 伸展树
### 想法
想利用局部性：

如果节点v被访问，随即转移至树根。

### 转移方法：
#### 一步一步：逐层伸展
转移复杂度过高，均摊O(n)，难以接受。【一系列的zig和zag旋转】

#### 一次2步的提升：双层调整
之字形的情况一样，跟一步一步
但是在zig-zig和zag-zag不一样
先旋转祖父节点，再旋转父节点

这样调整后，整个树的树高会大致缩减为原来的一般

有路径**折叠效果**：一旦访问坏节点，**对应路径**的长度将随之**减半**
分摊复杂度O(logn)

### 伸展算法
找到父亲和祖父，通过判断左右孩子区分zig、zag的情况，分别处理：类似3+4重构

每次伸展后更新高度

直到结束（有可能会有一次单旋）

### 查找
成功伸展至树根
失败把\_hot伸展至树根

### 插入
先查找
\_hot已经被换到了树根
然后把v插入成树根【原根与一个子树为一个子树，另一个子树为另一个子树】

### 删除
先查找
要删除的已经成为了树根
删除后然后把两个子树合并即可

合并：可以从右子树里找到最小的【左侧链下行】，成为新树根。

### 总和评价
1. 不用记录高度和平衡因子
2. 分摊复杂度O(logn)
3. 存在局部性的时候，效率可能会更高

缺点：不能保证单次最坏情况的出现，不适用于效率敏感的场合

## B树

### 引入动机
实现高效IO

### 定义

平衡的多路搜索树

m阶B-树，即m路平衡搜索树

**外部节点**的深度统一相等

所有**叶节点**的深度统一相等

树高 **h=外部节点的高度**

内部节点：
分支不超过m个，关键码不超过m-1个
不少于$$\lceil m/2 \rceil$$，树根只需要大于等于2

所以一般也叫(3,5)树，(2,4)树

### 实现
#### BTNode
一个指向父亲的引用
两个向量：第一个用来存关键码，n个；另一个用来存孩子的引用，n+1个

### 查找
在节点中顺序查找【1. 查找相比IO本来就小，没啥优化的必要；2. 在这里节点里的元素数目在几百K左右，二分查找效率反而更低】，如果没找到，就从引用往下一层。

失败查找必然终止于外部节点

#### 复杂度：O(h)
N个关键码的m阶B-树
最大树高：$$O(log_mN)$$，若m=256，树高只是BBST的1/7
最小高度：$$\Omega(log_mN)$$，若m=256，是1/8

B树高度的变化幅度有限

### 插入
查找，失败。\_hot标明了插入位置。
在节点中查找插入位置，插入，增加一个空子树指针。更新规模
如，上溢，分裂

#### 分裂
上溢的节点应该刚好有m+1个分支，m个关键码

取中位数$$s = \lfloor n/2\rfloor $$，左侧s个，中间一个，右侧剩下的，分为3部分

然后$$k_s$$上升一层，剩下两部分作为左、右孩子

父节点也可能会上溢

复杂度O(h)

### 删除
查找，返回的节点v。
如果v不是叶子，深入到v的右子树中，沿着最左侧向下，找到v的直接后继r。然后把v和后继r互换。
然后删掉v和引用。更新大小

如果下溢，做处理

#### 旋转
若v下溢，那么必然恰好是$$\lceil m/2 \rceil -2 $$个关键码，$$\lceil m/2 \rceil - 1$$个分支

下溢的节点先左顾右盼，如果兄弟有多的关键码，就借一个。借的时候要带上父节点，父节点下来，兄弟的上去

#### 合并
如果左右兄弟不存在或者借不出来。但是一定会存在一个兄弟。

直接把父亲拉下来，一起合并成一个大节点。

#### 复杂度O(h)

## 红黑树

目的：
一致性结构（Persistent structure）：支持对历史版本的访问

考虑空间复杂度
希望将版本间的差异空间复杂度控制在logn

红黑树可以将空间差异控制在O(1)

### 定义之一
增设外部节点，使之成为真二叉树

1. 树根：必为黑色
2. 外部节点：均为黑色
3. 其余节点：若为红，只能有黑孩子 //红之子、之父必黑
4. 外部节点到根：途中黑节点数目相等 //黑深度

### 直观理解
提升变换：把所有红色节点都提升到和它们的父亲同一层。

提升变换后就会变成一个(2,4)B-树

### 定义
高度需要重写，黑高度。

### 插入

搜索，插入的点x必然是末端节点。
插入，染红

如果它的父亲p是红的，需要修复

#### 双红缺陷
祖父节点必然存在且为黑，因为父亲是红的

考察p的兄弟，即x的叔父u

##### u是黑的
B树的对应节点是：
红 红 黑

需要一次3+4重构和一次染色

红 黑 红

##### u是红的
B树的对应节点是：
红 红 黑 红

处理上溢：以中为界【黑】，分为左右，中点上升

对应在红黑树上只需要改变颜色：
颜色：
p与u转黑，g转红

双红缺陷可能会向上传播

#### 复杂度
u为黑，有1-2次旋转，2次染色，随后完成
u为宏，没有旋转，只有3次染色，随后可能会再次双红，但必然上升2层

则总共最多1次重构，O(logn)次的染色

### 删除

直接调用BST的删除算法。

删除算法相当于删掉当前节点，然后用子树r替代

若x与r中有一个是红的，把r改为黑色即可。

#### 双黑缺陷
相当于是把一个节点删掉了，相当于B树的下溢缺陷

那么考虑x的父亲p和x的兄弟s。

##### BB1：s是黑的，且有一个红孩子t
将t的两个孩子，s的孩子，和p的孩子做3+4重构

染色：
tsp重命名为abc
r保持黑，a、c染黑，b继承p的颜色

相当于可以找兄弟借一个的情况

##### BB2：s是黑的，且两个孩子都是黑的
###### BB2-R：p为红
r保持黑，s转红，p转黑

而且不会影响上方
###### BB2-B：p为黑
s转红，r与p保持黑

可能会影响上方

##### BB3：s为红色
对p做一次旋转，把s和p的颜色互换
【相当于B树sp互换颜色】

此时情况转换为BB-1或BB-2R


#### 复杂度
1，旋转1-2，染色3，完成
2R，旋转0，染色2，完成
2B，旋转0，染色1，但可能继续双黑，但会上升
3，旋转1，染色2，转换为1或2R

最多
O(logn)次染色，1次3+4,1次单旋

# 9. 词典
## 散列Hashing
也可以译为哈希

call by value

存储每个元素称为桶bucket，直接存放或间接指向一个词条

散列函数：hash()

### 散列表和散列函数

尽可能降低冲突概率

#### 常用函数

##### 除余法

hash(key) = key % M

为了冲突概率小，M取素数。覆盖最充分，分布最均匀

##### MAD法

除余法的缺点：

	1. 不动点：hash(0) = 0
 	2. 相邻的关键码也必然相邻

改进：

hash(key) = ( a × key + b ) % M【b解决问题1，a解决问题2】

##### 更多的函数

数字分析selecting digits，挑选出某几位构成地址

平方取中mid-square，平方后取中间的几位

折叠法folding，分组后相加，也可以叠饼一样的折返加

位异或法XOR，分组后异或

##### 伪随机数法

不同平台的不同版本的伪随机数法不同，移植性很差，

#### 字符串转换为hashcode关键码

##### 多项式法

每个字符转换为一个整数，然后视作一个多项式的系数，然后算出来值

改进：不做多项式计算，把数的前5个比特和后27个比特互换位置，再累加


### 指定可行的预案

发生冲突，尽快排解

#### 多槽位multiple slots

桶单元细分槽位

但是：应该给每个桶预留多少个槽呢？过多浪费；无论预留多少，极端情况下都可能不够

##### 独立链

解决：用列表串接冲突词条separate chaining。缺点：指针需要额外空间；节点动态申请需要很多成本；空间未必连续，缓存功能几乎失效

#### 开放定址

open-addressing ~ closed hashing

每个词条都可能存放在任意一个桶中。

每个桶事先约定若干备用桶，构成一个查找链probing sequence/chain

##### 线性试探

一旦冲突，试探后一个紧邻的桶。

优点：充分利用缓存

缺陷：以往的冲突会导致后续的更多冲突clusting

##### 懒惰删除

冲突的一组词条存放在一个查找链里，如果删除的时候直接删除会切断查找链：后续词条明明存在，却访问不到。

lazy removal：仅做删除标记

#### 平方试探

一旦冲突，下一次试探$$[ \ hash(key) + 1^2,2^2,3^2...]\%M$$

优点：缓解数据聚集现象

缺点：若涉及外存，I/O激增，会损失一定的局部性，但是还可以，除非太倒霉

##### 明明存在空桶，却可能无法发现

M为素数，也只能涉及到$$\lceil M/2 \rceil $$，恰由查找链的前$$\lceil M/2 \rceil $$项取遍

故，如果M为素数，且装填因子不超过0.5，就一定能找出，否则不见得。【目前只装了不到50%的量进去，这样试探一定能找到一个空桶】

#### 双向平方试探

冲突后分别向前向后试探：+1 -1 +4 - 4 

若M=4k+3，则恰好能覆盖整个散列表

### 桶排序、计数排序

取决于规模n与取值范围[0,M)

复杂度：O(n+M)

若取值范围有限，存在大量重复，则会能在O(n)完成排序

#### 思路

例如随机输入的一段英语文本：

数一数每个字母的个数count，然后记下累计值accum【包括小的部分的总和】

该字母的位置应该就是[ accum(n-1),accum(n) )

# 优先级队列

循优先级访问

## 实现

### 向量

插入O(1)

删除Max$$\Theta (n)$$

获得Max$$\Theta (n)$$

难以接受

#### 有序序列

get和delete O(1)

插入O(n)

### 列表

列表同理，也不行

### BBST

O(logn)

但是BBST功能其实过于强大了

### 完全二叉堆

我们只需要偏序关系

向量为形，树为神。

完全二叉树：平衡因子处处非负的AVL【一棵满树，除了最底层的右侧缺失一段】

逻辑上等同于完全二叉树，物理上用向量实现。

若有父节点：$$ (i-1)/2 $$

左孩子：$$ 1+ 2 * i$$

右孩子：$$ (1+i)*2 $$

## 完全二叉堆实现

### 堆序性

每个节点的优先级不大于父节点

全局最大元素就应该是H[0]

### 插入和上滤

直接插到向量的末尾

#### 保证堆序性：上滤

若堆序性不满足，那么直接互换插入元素和它的父亲的位置。

while（e有父亲）：

比较父子大小，逆序交换，否则break

#### 复杂度

O(logn)

每次交换要3次赋值，3logn。可以做一些改进。

### 删除和下滤

删除，然后把末元素放到首元素的位置，先恢复结构性

#### 下滤

元素与孩子中较大的交换

j取i和i的两个孩子中最大的

while（i不等于j）交换

#### 复杂度

O(logn)

### 批量建堆

Heapification

#### 自下而上的下滤

自下而上，自右而左 下滤

不需要考虑叶子节点，只需要考虑内部节点即可。

##### 复杂度

每个节点调整需要的时间正比于**高度**

O(n)

## 堆排序

### 选择排序

初始化：建堆：O(n)

迭代取出最大元素排序；O(logn)

算法复杂度：O(nlogn)

#### 就地

每次对换堆秩0与秩-1

然后堆减1，下滤

## 左式堆

为了有效完成堆合并

保持堆序性，加入新条件：

单侧倾斜：节点分布偏向于**左侧**，合并操作只涉及到右侧

复杂度可以到O(logn)

结构性破坏了，但是堆序性才是本质

### 空节点路径长度

Null Path Length：NPL

引入所有的外部节点，转换为一棵真二叉树。

npl(NULL)=0

$$npl(x) = 1+ min(\  npl( lc(x) ), npl(rc(x))\  )$$

npl(x) = x到外部节点的最近距离，也是以x为根的最大**满子树**的高度

### 左倾性&左式堆

npl( lc(x) ) >= npl( rc(x) )

左倾：左孩子的npl不小于右孩子的npl

左式堆：每个节点都是左倾的

推论：左式堆的npl(x) = 1+右子堆的npl

左倾性与堆序性，相容而不矛盾

左式堆倾向于分布在左侧分支，但是不意味着左子堆的规模和高度一定大于右子堆

### 右侧链

从x出发，一路按右分支前进

根的右侧链的终点，一定是全堆最浅的外部节点

这意味着，右侧链长d的左式堆，一定有一个高度为d的满子树，至少有$$2^{d+1}-1$$个节点，如果总节点是n个，d最多O(logn)

### 左式堆实现

左式堆不满足结构性，所以用二叉树来派生

### 递归合并

a、b两个子树，先把a的右子树和b合并，合并完作为a的右子树。最后比较NPL，如果有必要交换一下。



#### 实现

递归基：如果一个为空，返回另一个

比较a、b的大小，保证数值上a>=b

递归地将a的右子堆与b合并

合并后的子堆作为a的右子堆，判断一下npl大小，有必要的话互换，更新npl

#### 复杂度

合并过程只涉及到了右侧链，故O(logn)

### 插入与删除

借用合并。

#### 插入

就认为是一个只有一个节点的左式堆，进行合并

#### 删除

delMax

直接删除根节点，然后把子堆合并

# 11 串
字符串：一系列字符构成的长度有限的序列。不要求字符互异，线性序列。

字符串相等：长度相等，且对应的字符均相等

空串：长度为0的串。是任何串的子串、前缀、后缀。

indexOf(P)接口：判断一个串是否是当前字符串的子串

## 串匹配
文本串T，$$|T|=n$$
模式串P，$$|P|=m$$
通常有$$n>>m>>2$$

问题层次：
detection：P**是否**出现？
location：首次**在哪里**出现？（核心问题）
counting：共有**几次**出现？
enumeration：各出现**在哪里**？

### 算法评测
测量与评估串匹配算法的性能的方法：

随机T + 随机P ？ 不行。

以二进制串为例，长度为m的P有$$2^m$$个，而T中匹配的子串最多n个。匹配成功的概率非常小$$<10^{-25}$$。

随机T，对成功、失败的匹配情况分别考虑。
成功：在T中，随机取出长度为m的子串作为P，分析平均复杂度
失败：采用随机的P，统计平均复杂度

### 蛮力匹配
自左向右，以字符为单位，依次移动模式串。

#### 实现：版本1
约定尾部有个哨兵```\0```，不计入串长。
用```i```和```j```分别指示当前在文本串和模式串中字符
那么两者的对齐位置是```i-j```，匹配失败时，```j=0，相当于j-j，那么i=i - (j-1)```，成功时i和j自增1，当j和i越过上界时，结束循环

返回```i-j```，失败的时候返回的值大于最大的合法位置```n-m```

#### 实现：版本2
区别：j依旧是模式串中的当前字符，而i是对齐的位置。文本串中当前字符是```i+j```

#### 复杂度
成功：
最好情况：一轮比对就确定匹配O(m)
最坏情况：O(m×n)

字母表$$|Σ|$$越小，最坏情况的**概率**越高
m越大，最坏情况的**后果**更严重


当字母表增大，最坏情况概率会急剧下降，期望复杂度可以达到线性O(n)

## KMP
最坏情况下复杂度也可以达到O(n)

前缀中存在大量重复。

向后滑动模式串，让一个新的P[j]与T[i]对齐，从这里开始重新继续比较。

1. 大幅度向后滑动模式串
2. 避免前缀中的重复比对

### 查询表
只与模式串有关，与主串无关。

在j处失败后，用next[j]替代j。

主算法
1. 构造next表，只与P有关
2. 两个指针，i，j，分别指向文本串和模式串中参与比对的字符
3. i，j不越界的情况下循环，成功【在相等条件前增加一个j < 0 or的条件】则共同+1
4. 失败的情况下，```j=next[j]```，i不变
5. ```return i-j```

#### 理解
next[j]=t

自匹配

在某一次失配的时候，已经匹配过的前缀部分记为X
则移动的必要条件是，X中有一个长度为t的前缀，与长度为t的后缀，相等。
移动的距离是j-t

可以表示为$$P[0,t) == P[j-t,j),\  0\le t<j$$

我们希望位移量j-t最小，所以t取最大的

令next[0] = -1【对应if语句中加的j<0】-1认为是一个通配符


#### 实现
递推：
如果已知next[0,j]，如何求next[j+1]

next(j)，就是P[0,j)中，最大自匹配的真前缀和真后缀的长度
所以$$next[j+1] \le next[j] + 1$$
即t最多增长一个单位，取等号的充要条件是$$P[j] == P[ next[j] ]$$，模式串中j处的字符，与next表中的继任者相等。

如果不相等：
因为前缀要满足自相似性，那么把j替换成n(j)，如果还不行，就把n(j)替换成n( n(j) )，以此类推。一旦相等，就加一。

那么next[j+1]的可能值有：
1 + next[j]
1 + next[ next[j] ]
...
next[j]<j，因为是个真前缀真后缀，所以一定会收敛终止。

#### 实现
相当于是自己匹配自己，框架与KMP主算法差不多
1. 初始化N[0] = -1
2. 循环：匹配的情况下，N[j+1] = t+1;
3. 失配t = N[t]

### 复杂度分析
精准估计：
令$$k = 2 * i - j$$
在算法中：
如果匹配成功，i++,j++，k会+1
如果匹配失败，j =  next[j]，则k至少+1

所以k必然随迭代单调递增，所以迭代步数必然小于等于k

k初始是0，算法结束时，i最多n-1，j最小-1，所以复杂度O(n)

### 瑕疵
经验和教训

经验：已经匹配过的子串，通过自相似已经获得了
教训：当前要匹配的这个字符其实已经知道了**一定不是什么**，但是目前的KMP算法会不断的重复匹配这个字符


### 改进的Next表
匹配成功的情况需要改进：

原来 N[j+1] = t+1

现在：
目前这个字符与原来字符不相等的情况，和原来一样 N[j] = t
相等的情况：用N[j] = N[t]【相当于跳过了当前位置，继续下一次】

## BM算法

串匹配的时候，相等和不等的成本不一样，相等要都相等，但是一旦发现一个不等，立刻就可以知道不等

### 坏字符Bad-Character

匹配过程中：
每一次的局部：多次成功，一次失败
整体：一次成功，多次失败

想尽可能快的排除掉无效位置，加速失败
KMP也是这样

#### 思路
字母表规模不是很小的话，单次比对成功的概率远远小于失败的概率

而模式串中越靠后的失败，越可能排除掉更多的对其位置。所以每次比对从末字符开始，从右向左比对。

#### 详细分析

用蛮力版本二改进：

一旦发现$$T[i+j] = X \ne Y = P[j]$$，那么X和Y后面的后缀是相同的。

Y称为坏字符：从后向前匹配到这里失败了。

那么下一次对齐的时候，模式串里的这个字符也应该是X才行。

为了避免回溯，希望移动距离最小，所以选模式串里最靠后的X【X后的后缀中没有X】。移动距离：j-bc[X]

X前的长度：bc[X]。极端情况：模式串没有X，bc[X]=-1

若X太靠后，j-bc[X] < 0了，就直接移动一个字符

### bc表

1. bc表与字母表等长
2. 初始化为-1
3. 自左向右扫描模式串，每个字母用所在的秩更新表中的内容。【画家算法，最后留下的是最靠后的】

空间复杂度：O(s)
时间复杂度：O(s+m)【第一趟初始化循环可以省略，可以改进至O(m)，但没讲】

### 复杂度
失败
最好情况：O(n/m)

字母表越大，这个算法效果越好

最差情况：O(n×m)

#### 好后缀Good-Suffix

已经匹配过的后缀下一次也应该是一样的

MS子串和ss表：
MS[j]：以P[j]为末字符的子串，同时与后缀最长匹配。
ss[j]=|MS[j]|，即ss表的第j项就是MS子串的长度

##### ss构造gs
1. ss[j] = j + 1

MS子串足够长，已经成为了一个前缀。
m-j-1必然是gs[i]的一个候选

2. SS[J] <= J

这时候考虑的长度也是m-j-1

##### 构造ss表

蛮力策略：O(m^2)

自后向前逆向扫描，O(m)


#### BM_GS算法复杂度分析
BM：
空间：字母表+m
预处理：O(字母表+m)
最好：n/m
最差：n+m

### 几种算法的复杂度
蛮力算法：n+m   ~  n*m
KMP： n+m
BC：n/m  ~  n*m
BC+GS：n/m  ~  n+m

## Karp-Rabin算法：串即是数
将一个串，视作一个整数

每个有限维的自然数向量，唯一对应于一个自然数：
$$<a_1, a_2,...,a_n> ~ p(1)^{1+a_1} × p(2)^{1+a_2}×...p(n)^{1+a_n}$$

p(n)是第n个素数【2,3,5,7,11,13,17,19，....】

而且质因数分解还可以还原。

### 算法：散列
一个英文字符串可以看作是26进制的一个数。

但是如果字符集很大，对应的指纹会非常庞大。

那么对指纹进行散列。
若取M=97
则每次比对指纹
P = 8 2 8 1 8
hash(P) = 77

因为散列可能会冲突，所以最后要严格匹配，最终来确定。

### 快速指纹计算
hash()的计算复杂度成为O(1)，那么最终算法就是线性的

# 排序

## 快速排序

将序列分为两个子序列，要求左侧的子序列的最大值小于或等于右序列的最小值

+ 轴点：

左侧的元素都不比它大，右侧的元素都不比它小

坏消息：原始序列未必存在轴点。

必要条件：轴点必然已经就位了。

好消息：通过适当交换，任一元素可能成为轴点。

### 思路

先选一个轴点候选，通常是首元素。用两个指针lo和hi把序列分成L，U，G三段。

其中L<=轴点候选，轴点候选<=G，U未知

先将首选元取出，作为候选轴点，现在首元素就认为是空闲的。

然后从后面开始考察，如果元素大于等于候选轴点，hi向前移动

直到元素小于轴点，那么把它移动到空闲的前面，从前面继续开始判断

直到最后U只有一个节点，把候选轴点填进去就好。

### 性能分析

1. 不稳定，会改变相同元素的位置。
2. 可以就地实现，只需要保存一个单元和指针
3. 时间复杂度：最好情况都很均衡，O(nlogn)，最差情况O(n^2)
4. 平均情况O(nlogn)，常系数小

### 变种

候选轴点还是首元素，顺序从LUG变成LGU

还是从U中往LG中加，往L中加，互换U0与G0，往G中加，指针后移即可。

G相当于滚动后移。最后有一次候选轴点与L末的互换。

#### 分析

就地

O(n)

不具有稳定性

## 选取问题

### 众数

k-selection：选中从小到大排列，次序为k的元素

median中位数：从小到大排列，次序为**n/2的下整**的元素

majority众数：和之前的不太一样。是指，无序向量中，有一半**以上**的元素都是m，则称之为众数【严格大于】



必要性1：众数若存在，必然是中位数。

只要能找到中位数，那么只需要遍历一次O(n)，就可以知道是不是众数



必要性2：众数必然是频繁数

mode频繁数：一组数据中出现次数最多的



但是这两个的时空复杂度都不太行。



减而治之：

若去掉一个前缀P（偶数），P中的x恰好出现一半，那么A-P如果有众数m，A也有，而且一样

证明：最后总是要花O(n)验证，假设存在众数，x=m，m与其他元素的的数量差保持不变；不等于数量差也不会变小。



首元素当做x，直到x是P的一半，去掉。用1个计数器。一趟扫描。



## 选取k

linearSelect()

设定Q为一个小的常数

0. 如果序列长度小于Q，那么直接随便用一个方法选k

1. 把A划分成若干子序列，序列长度为Q，有n/Q个

2. 每个子序列全排列，方法无所谓，找到每个子序列的中位数

3. 找到中位数序列的中位数M，通过递归调用linearSelect

4. 所有小于M的数归入L，等于的为E，大于的为G。

5. 如果L足够长，L的长度大于等于k，在L中递归寻找k

   再如果k小于L+E的长度，**返回M**

   其他情况就是G足够长，k落在了G里，递归查找G中第k-|L|-|E|个元素

### 复杂度

保证1/Q + 3/4 < 1

可以保证O(n)【但是常系数非常大，该算法只有理论意义】

## 希尔排序

将输入视为一个矩阵，逐列排序

w列，w-sorting。如果已经有序，w-ordered。然后不断让矩阵更窄。

直到1-sorting

各种w的值构成了一个序列：步长序列step sequence

$$w_1 = 1,w_2,w_3,...$$

序列单调。所以希尔排序也叫递减增量法

不同的步长序列，会有不同的效果。



矩阵重排只需要算一下秩就可以



逐列排序要有输入敏感性：插入排序

由g，h的线性组合所能表示的数里，最大的一个不能表示的数为：

$$x(g,h)=(g-1)*(h-1)-1$$

h-ordered：间隔h的两个数（x，x+h）都是有序的

任何一个序列做过h-sorting后必然是h-ordered

定理：任何一个原先g-ordered的序列，在h-sorting后，还是g-ordered的

一个g-ordered且h-ordered的序列，必然也是g+h - ordered，任何g，h的任何线性组合-ordered



PS序列

Pratt序列

Sedgewick序列